{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################       \n",
    "#Script Name    :                                                                                              \n",
    "#Description    :                                                                                 \n",
    "#Args           :                                                                                           \n",
    "#Author         : Nikhil Rao in R, converted to Python by Nor Raymond                                              \n",
    "#Email          : nraymond@appen.com                                          \n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fail Rate Reports for Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import warnings\n",
    "from functools import reduce\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "except:\n",
    "    \n",
    "    os.chdir('..')\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "# import data_processing module\n",
    "import src.data.data_processing as data_processing\n",
    "# import data_processing module\n",
    "import src.data.data_cleaning as data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_selection(languages):\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            language_index = int(input(\"\\nPlease select the number of the Language you are assessing: \"))\n",
    "            if language_index < min(languages.index) or language_index > max(languages.index):\n",
    "                print(f\"\\nYou must enter numbers between {min(languages.index)} - {max(languages.index)}... Please try again\")\n",
    "                continue\n",
    "            elif language_index == \"\":\n",
    "                print(\"\\nYou must enter any numbers\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"\\nYou have selected {language_index} for {languages.iloc[language_index, 0]}\")\n",
    "                language_selected = languages.iloc[language_index, 0]\n",
    "                break\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"\\nYou must enter numerical values only... Please try again\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return language_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Language Modification - getting the overall time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Language Modification\n",
    "def get_time_taken(df, language_selected):\n",
    "\n",
    "    # Filter data based on selected language\n",
    "    dfr = df[df['Language'] == language_selected]\n",
    "\n",
    "    # Time Taken by Item\n",
    "    dfr[\"Time_Taken_Seconds\"] = (dfr['_created_at'] - dfr['_started_at']).dt.seconds\n",
    "\n",
    "    # Time Taken Overall\n",
    "    dfr_grouped = dfr.groupby('_worker_id').sum('Time_Taken_Seconds')\n",
    "    dfr_grouped[\"Time_Taken_Minutes_Overall\"] = dfr_grouped[\"Time_Taken_Seconds\"] / 60\n",
    "    dfr_grouped = dfr_grouped.reset_index()\n",
    "    dfr = pd.merge(dfr, dfr_grouped[[\"Time_Taken_Minutes_Overall\", \"_worker_id\"]], how = 'left', on = '_worker_id')\n",
    "\n",
    "    return dfr\n",
    "\n",
    "def get_time_taken_all(language_selected, rc, v1, v2):\n",
    "    \n",
    "    df_list = [rc, v1, v2]\n",
    "    keys = [\"rcR\", \"v1R\", \"v2R\"]\n",
    "    df_time = {}\n",
    "    \n",
    "    for df, key in zip(df_list, keys) :\n",
    "\n",
    "        dfr = get_time_taken(df, language_selected)\n",
    "        df_time[key] = dfr\n",
    "\n",
    "    rcR, v1R, v2R = df_time[\"rcR\"], df_time[\"v1R\"], df_time[\"v2R\"]    \n",
    "    \n",
    "    return rcR, v1R, v2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for pilot variant selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_1_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]     \n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "\n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D'):\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "    \n",
    "    elif pilot_var_selected == 'Pilot 3A':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    return selector_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_2_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "    \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "\n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]\n",
    "        \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answer', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answer', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', 'Tenure', '_unit_id','Fail_Rate'], [True, True ,True, False]\n",
    "        \n",
    "        drop_cols, explode, join_on, select3 = [],[],[],[]\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "              \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "              \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "                 \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "\n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "\n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        select3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a',\n",
    "                'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Count_of_Test_Takers', 'Total_Test_Takers',\n",
    "                'Overall_Fail_Rate', 'Answers', 'a_and_b_are_not_related', 'a_and_b_are_related', 'a_and_b_have_the_same_meaning',\n",
    "                'a_is_more_specific_than_b', 'b_is_more_specific_than_a'] \n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "              \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "              \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        select3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a',\n",
    "                'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Count_of_Test_Takers', 'Total_Test_Takers',\n",
    "                'Overall_Fail_Rate', 'Answers', 'a_and_b_are_not_related', 'a_and_b_are_related', 'a_and_b_have_the_same_meaning',\n",
    "                'a_is_more_specific_than_b', 'b_is_more_specific_than_a']\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "                      \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "                      \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 2B-A':\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "                      \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "                      \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : []}\n",
    "            \n",
    "    return selector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_3_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        # for rc_fail_rate_1A_1B\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "         \n",
    "        explode =  ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds','_unit_id', 'title', \n",
    "                    'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc_answer_actual_1A_1B\n",
    "        select2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                       '_unit_id', 'title', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate_1A_1B\n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'a', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : [], \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "               \n",
    "        # for rc_fail_rate\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                   '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc\n",
    "        select2 = ['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']\n",
    "        \n",
    "        #for melt_rc_answer_actual\n",
    "        select3 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure' ,'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                    '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate\n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : select3, \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # for rc_fail_rate\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "                   '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc\n",
    "        select2 = ['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']\n",
    "        \n",
    "        #for melt_rc_answer_actual\n",
    "        select3 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "                    '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate\n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : select3, \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    return selector_3\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_4_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'aa', 'ra', 'a', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', '_unit_id', 'q', 'Fail_Rate'], [True, True, True, True, False]\n",
    "        \n",
    "        selector_4 = {\"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}        \n",
    "            \n",
    "    elif (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Actual_Answer', 'Rater_Answer', \n",
    "                                    'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id', 'Question', 'Fail_Rate'], [True, True, True, False]\n",
    "        \n",
    "        selector_4 = {\"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "        \n",
    "    return selector_4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for calculating Fail Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 3A, 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ---------------------------------------------------------------\n",
    "\n",
    "def v1_fail_rate(v1R, selector_1):  #Valid for Pilot 3A, 1C\n",
    "    \n",
    "    vR_temp = v1R[selector_1['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0\n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending = selector_1['sort_order'])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1(v1R, selector_1):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate(v1R, selector_1)\n",
    "    \n",
    "    return v1_actual_correct_by_question\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "\n",
    "def v2_fail_rate(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Overall_Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values'], ascending = selector_2['sort_order'])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 . Note Pilot 1C,1D seem to have this disabled, but it's not making sense as Fail Rate should have Score = 0.\n",
    "    if (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)'):\n",
    "        vR_grouped = vR_grouped\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 3A' or pilot_var_selected == 'Pilot 2A' or \n",
    "          pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D'):\n",
    "        vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "    # drop Score columns\n",
    "    vR_grouped = vR_grouped.drop(selector_2['drop_cols'], axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].fillna('Null')\n",
    "    \n",
    "    vR_fail_rates  = pd.pivot_table(vR_fail_rates, \n",
    "                           index = selector_2['explode'],\n",
    "                           values='Rate', columns=['rater_answer']).reset_index()\n",
    "    vR_fail_rates.columns.name = None # remove name for columns\n",
    "    \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].replace('Null', np.nan)\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_fail_rates = vR_fail_rates.drop_duplicates()\n",
    "    \n",
    "    return vR_fail_rates \n",
    "\n",
    "def merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2, pilot_var_selected):\n",
    "    \n",
    "    v2_fail_rates = pd.merge(v2_actual_correct_by_question_with_answer, v2_actual_correct_by_question, how = 'left', \n",
    "                            on = selector_2['join_on'])\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 2B-A': # maybe add 2D here!\n",
    "        v2_fail_rates = v2_fail_rates\n",
    "    elif (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        v2_fail_rates = v2_fail_rates[selector_2['select3']]\n",
    "    \n",
    "    return v2_fail_rates\n",
    "\n",
    "def generate_report_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate(v2R, selector_2)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "    v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2, pilot_var_selected)\n",
    "    \n",
    "    return v2_fail_rates\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "\n",
    "def rc_fail_rate(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select1']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    # Dropping columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "                                                                                               'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return rc_answer\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_assign(rc_choices, q_list, choice_list):\n",
    "    \n",
    "    df=[]\n",
    "    for ql in q_list:\n",
    "        for cl in choice_list:\n",
    "            df_temp_1 = rc_choices[rc_choices['variable'].str.contains('question_' + str(ql))]\n",
    "            df_temp_2 = df_temp_1[df_temp_1['variable'].str.contains('choice_' + str(cl))]\n",
    "            df_temp_2['Question'] = 'Question ' + str(ql)\n",
    "            if cl == 1 :\n",
    "                df_temp_2['Answer'] = 'a'\n",
    "            elif cl == 2 :\n",
    "                df_temp_2['Answer'] = 'b'\n",
    "            elif cl == 3 :\n",
    "                df_temp_2['Answer'] = 'c'\n",
    "            df.append(df_temp_2)\n",
    "            \n",
    "    rc_choices = pd.concat(df)\n",
    "    return rc_choices\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select2']]\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_temp = vR_temp.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    vR_temp = pd.melt(vR_temp, id_vars=['Language', '_unit_id', 'title', 'test_'])\n",
    "    \n",
    "    rc_choices = vR_temp\n",
    "    \n",
    "    q_list, choice_list = [1,2,3,4], [1,2,3]\n",
    "    rc_choices = melt_rc_assign(rc_choices, q_list, choice_list)\n",
    "    rc_choices = rc_choices[['Language', '_unit_id', 'title', 'test_', 'Question', 'Answer', 'variable', 'value']]\n",
    "    rc_choices = rc_choices.sort_values(['Language', 'title', 'test_', 'Question', 'Answer'])\n",
    "    \n",
    "    actual_answer = rc_choices\n",
    "    rater_answer = rc_choices\n",
    "    \n",
    "    return rc_choices, actual_answer, rater_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual(rcR, selector_3):\n",
    "    \n",
    "    vR_temp = rcR[selector_3['select3']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Rater_Answer'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['Actual_Answer'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_3'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode2']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Rater_Answer', 'Actual_Answer', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Rater_Answer', \n",
    "                                                                                                                                'Actual_Answer','Question', \n",
    "                                                                                                                                'Difficulty', \n",
    "                                                                                                                                'Google_Translate_Error', \n",
    "                                                                                                                                'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate(rc_answer, selector_3):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(selector_3['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_3['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_3['sort_values'], ascending = selector_3['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3(rcR, selector_3):\n",
    "    \n",
    "    rc_answer = rc_fail_rate(rcR, selector_3)\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate(rc_answer, selector_3)\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "\n",
    "def rc_q_s_pass_rate_answer(rc_answer_actual, selector_4):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer_actual.groupby(selector_4['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_4['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_4['sort_values'], ascending = selector_4['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer\n",
    "\n",
    "def join_rc_q_s_pass_rate_answer(rc_question_skill_pass_rate_answer, actual_answer, rater_answer):\n",
    "    \n",
    "    first_join = rc_question_skill_pass_rate_answer\n",
    "    first_join = pd.merge(first_join, actual_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Actual_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    first_join = first_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = pd.merge(first_join, rater_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Rater_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    second_join = second_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = second_join[['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Difficulty', 'register', 'Skill', 'Question',\n",
    "                               'Actual_Answer', 'value_x', 'Rater_Answer', 'value_y', 'Count', 'Total', 'Fail_Rate']]\n",
    "  \n",
    "    second_join = second_join.rename(columns = { \"Actual_Answer\" : \"Actual_Answer_Letter\", \n",
    "                                       \"value_x\" : \"Actual_Answer_Text\",\n",
    "                                       \"Rater_Answer\" : \"Rater_Answer_Letter\",\n",
    "                                       \"value_y\" : \"Rater_Answer_Text\"})\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = second_join\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "\n",
    "def generate_report_4(rcR, selector_3, selector_4):\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = rc_q_s_pass_rate_answer(rc_answer_actual, selector_4)\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = join_rc_q_s_pass_rate_answer(rc_question_skill_pass_rate_answer, actual_answer, rater_answer)\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 1A-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ------------------------------------------------------------------\n",
    "\n",
    "def v1_fail_rate_1A_1B(v1R, selector_1):  #Valid for Pilot 1A-1B\n",
    "    \n",
    "    vR_temp = v1R[selector_1['select1']]\n",
    "       \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending=selector_1['sort_order'])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1_1A_1B(v1R, selector_1):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate_1A_1B(v1R, selector_1)\n",
    "    \n",
    "    return v1_actual_correct_by_question\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "\n",
    "def v2_fail_rate_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values'], ascending = selector_2['sort_order'])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "    v2_actual_correct_by_question_with_answer = vR_grouped\n",
    "    \n",
    "    return v2_actual_correct_by_question_with_answer\n",
    "\n",
    "def generate_report_2_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate_1A_1B(v2R, selector_2)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2_1A_1B(v2R, selector_2)\n",
    "\n",
    "    return v2_actual_correct_by_question_with_answer\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "\n",
    "def rc_fail_rate_1A_1B(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select1']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    # Dropping columns  drop_cols_1\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['a'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['q'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['d'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ge'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['a', 'q', 'd', 'ge', 'skill']] = vR_temp[['a', 'q', 'd', 'ge', 'skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['a'])  # remove rows with NaN values in Score \n",
    "    vR_temp['a'] = vR_temp['a'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return rc_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual_1A_1B(rcR, selector_3):\n",
    "    \n",
    "    vR_temp = rcR[selector_3['select2']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['a'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ra'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['aa'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['q'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['d'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ge'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_3'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode2']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['a', 'ra', 'aa', 'q', 'd', 'ge', 'skill']] = vR_temp[['a', 'ra', 'aa', 'q', 'd', 'ge', 'skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['a'])  # remove rows with NaN values in Score \n",
    "    vR_temp['a'] = vR_temp['a'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate_1A_1B(rc_answer, selector_3):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(selector_3['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_3['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['a'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_3['sort_values'], ascending = selector_3['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3_1A_1B(rcR, selector_3):\n",
    "    \n",
    "    rc_answer = rc_fail_rate_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate_1A_1B(rc_answer, selector_3)\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "\n",
    "def rc_q_s_pass_rate_answer_1A_1B(rc_answer_actual, selector_4):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer_actual.groupby(selector_4['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_4['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['a'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_4['sort_values'], ascending = selector_4['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer\n",
    "\n",
    "def generate_report_4_1A_1B(rcR, selector_3, selector_4):\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer_final = rc_q_s_pass_rate_answer_1A_1B(rc_answer_actual, selector_4)  #THIS ONE\n",
    "   \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected):\n",
    "    \n",
    "    if (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "        pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or pilot_var_selected == 'Pilot 2D' or\n",
    "        pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # Report 1 - Near Exact Match - v1_actual_correct_by_question\n",
    "        selector_1 = report_1_selector(pilot_var_selected)\n",
    "        v1_actual_correct_by_question =  generate_report_1(v1R, selector_1)\n",
    "\n",
    "        # Report 2 - Close Match - v2_fail_rates\n",
    "        selector_2 = report_2_selector(pilot_var_selected)\n",
    "        v2_fail_rates = generate_report_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "        # Report 3 - Reading Comprehension - rc_question_skill_pass_rate\n",
    "        selector_3 = report_3_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate = generate_report_3(rcR, selector_3)\n",
    "\n",
    "        # Report 4 - RC with Answers - rc_question_skill_pass_rate_answer_final\n",
    "        selector_4 = report_4_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate_answer_final = generate_report_4(rcR, selector_3, selector_4)\n",
    "\n",
    "        # store all 4 reports into a dictionary set\n",
    "        list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "                            \"Close Match\" : v2_fail_rates,\n",
    "                            \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "                            \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}\n",
    "\n",
    "        if run_value == 'Deployment':\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = {\"deployment_rc\" : rc,\n",
    "                                \"deployment_v1\" : v1,\n",
    "                                \"deployment_v2\" : v2}\n",
    "\n",
    "        else:\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = { pilot_var_selected + \"_rc\" : rc,\n",
    "                                  pilot_var_selected + \"_v1\" : v1,\n",
    "                                  pilot_var_selected + \"_v2\" : v2}\n",
    "            \n",
    "            \n",
    "    elif pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        # Report 1 - Near Exact Match - v1_actual_correct_by_question\n",
    "        selector_1 = report_1_selector(pilot_var_selected)\n",
    "        v1_actual_correct_by_question =  generate_report_1_1A_1B(v1R, selector_1)\n",
    "\n",
    "        # Report 2 - Close Match - v2_fail_rates\n",
    "        selector_2 = report_2_selector(pilot_var_selected)\n",
    "        v2_fail_rates = generate_report_2_1A_1B(v2R, selector_2)\n",
    "\n",
    "        # Report 3 - Reading Comprehension - rc_question_skill_pass_rate\n",
    "        selector_3 = report_3_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate = generate_report_3_1A_1B(rcR, selector_3)\n",
    "\n",
    "        # Report 4 - RC with Answers - rc_question_skill_pass_rate_answer_final\n",
    "        selector_4 = report_4_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate_answer_final = generate_report_4_1A_1B(rcR, selector_3, selector_4)\n",
    "\n",
    "        # store all 4 reports into a dictionary set\n",
    "        # v2_fail_rates = v2_actual_correct_by_question_with_answer\n",
    "        list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "                            \"Close Match\" : v2_fail_rates,\n",
    "                            \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "                            \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}\n",
    "\n",
    "        if run_value == 'Deployment':\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = {\"deployment_rc\" : rc,\n",
    "                                \"deployment_v1\" : v1,\n",
    "                                \"deployment_v2\" : v2}\n",
    "\n",
    "        else:\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = { pilot_var_selected + \"_rc\" : rc,\n",
    "                                  pilot_var_selected + \"_v1\" : v1,\n",
    "                                  pilot_var_selected + \"_v2\" : v2}\n",
    "\n",
    "    \n",
    "    return list_of_datasets, list_of_summaries\n",
    "\n",
    "def file_check_create(root_path, config, language_selected, run_value, pilot_var_selected):\n",
    "    \n",
    "    if run_value == 'Deployment':\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "        \n",
    "        folder_tag = 'Deployment Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, pilot_var_selected, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "            \n",
    "        folder_tag = 'Grand Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "        \n",
    "    return run_folder, analysis_folder, folder_tag\n",
    "\n",
    "def write_fail_report_to_excel(run_folder, list_of_datasets, encoding=None):\n",
    "    \n",
    "    with pd.ExcelWriter(os.path.join(run_folder, 'language_fail_rates.xlsx')) as writer:  \n",
    "        for key, value in list_of_datasets.items():\n",
    "            value.to_excel(writer, sheet_name=key, index=False, encoding=None)\n",
    "            \n",
    "def write_summary_to_excel(analysis_folder, list_of_summaries, encoding=None):\n",
    "    \n",
    "    folders = ['RC', 'V1', 'V2']\n",
    "    for lists, f in zip(list_of_summaries.items(), folders):\n",
    "        key, value = lists[0], lists[1]\n",
    "        #value.to_csv(os.path.join(os.path.join(analysis_folder,f), key + '.csv'), index=False, encoding=None)\n",
    "        value.to_excel(os.path.join(os.path.join(analysis_folder,f), key + '.xlsx'), index=False, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data processing in progress...\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "PASS: All files exists!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the type of run e.g. Deployment, Pilot 1, Pilot 2, Pilot 3 .... etc.:  Pilot 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run type: Pilot 3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the pilot subfolder name e.g. Pilot 1A, Pilot 2C, Pilot 3A-B .... etc.:  Pilot 3A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pilot subfolder: Pilot 3A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you know the 'Language' and/or 'Market code' for this file? (y/n) :  y\n",
      "\n",
      "Please enter the Language:  Turkish\n",
      "\n",
      "Please enter the Market code: eg. EN-EN for English :  TR-TR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting automated data cleaning....\n",
      "\n",
      "Dataframe created from RC file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Missing columns inserted into 'Data' sheet.\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market  _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR    45488787     24    1.000000  Pilot 3A\n",
      "1  Turkish  TR-TR    45638661     24    1.000000  Pilot 3A\n",
      "2  Turkish  TR-TR    45638934     24    1.000000  Pilot 3A\n",
      "3  Turkish  TR-TR    45758795     23    0.958333  Pilot 3A\n",
      "4  Turkish  TR-TR    45764098     24    1.000000  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language           _id question_no_1 question_no_2 question_no_3  \\\n",
      "0  Turkish  5.868341e+09             a             c             b   \n",
      "1  Turkish  5.868379e+09             a             c             b   \n",
      "2  Turkish  5.868379e+09             a             c             b   \n",
      "3  Turkish  5.868425e+09             a             c             b   \n",
      "4  Turkish  5.868942e+09             a             c             b   \n",
      "\n",
      "   question_no_4  question_no_5  \n",
      "0            NaN            NaN  \n",
      "1            NaN            NaN  \n",
      "2            NaN            NaN  \n",
      "3            NaN            NaN  \n",
      "4            NaN            NaN  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : RC - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : RC - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[92mPASS\u001b[0m: The columns in the 'Data' sheet are identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_1 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR   45488787   40.0    0.930233  Pilot 3A\n",
      "1  Turkish  TR-TR   45638661   39.0    0.906977  Pilot 3A\n",
      "2  Turkish  TR-TR   45638934   40.0    0.930233  Pilot 3A\n",
      "3  Turkish  TR-TR   45758795   39.0    0.906977  Pilot 3A\n",
      "4  Turkish  TR-TR   45764098   40.0    0.930233  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language         _id rater_answer a_domain a_register b_domain b_register\n",
      "0  Turkish  5868295106          yes   season    neutral   season    neutral\n",
      "1  Turkish  5868300856          yes   season    neutral   season    neutral\n",
      "2  Turkish  5868300866          yes   season    neutral   season    neutral\n",
      "3  Turkish  5868359497          yes   season    neutral   season    neutral\n",
      "4  Turkish  5868406548          yes   season    neutral   season    neutral\n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_1 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_1 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_2 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR   45488787   89.0        0.89  Pilot 3A\n",
      "1  Turkish  TR-TR   45638661   95.0        0.95  Pilot 3A\n",
      "2  Turkish  TR-TR   45638934   92.0        0.92  Pilot 3A\n",
      "3  Turkish  TR-TR   45758795   93.0        0.93  Pilot 3A\n",
      "4  Turkish  TR-TR   45764098   95.0        0.95  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language           _id                   rater_answer a_domain a_register  \\\n",
      "0  Turkish  5.868301e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "1  Turkish  5.868344e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "2  Turkish  5.868344e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "3  Turkish  5.868410e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "4  Turkish  5.868781e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "\n",
      "  b_domain b_register  \n",
      "0     time    neutral  \n",
      "1     time    neutral  \n",
      "2     time    neutral  \n",
      "3     time    neutral  \n",
      "4     time    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_2 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_2 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Automated data cleaning completed. Cleaned excel files are located in data > processed > Pilot 3 folder. \n",
      "\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "\n",
      "\n",
      "      Pilot     Variation                               Comments\n",
      "0   Pilot 1   Pilot 1A-1B               Added in pilot variation\n",
      "1   Pilot 1      Pilot 1C               Added in pilot variation\n",
      "2   Pilot 1      Pilot 1D               Added in pilot variation\n",
      "3   Pilot 1      Pilot 1E               Added in pilot variation\n",
      "4   Pilot 1  Pilot 1E(ES)               Added in pilot variation\n",
      "5   Pilot 2      Pilot 2A               Added in pilot variation\n",
      "6   Pilot 2    Pilot 2A-A  DO NOT USE: Manual Processing for now\n",
      "7   Pilot 2    Pilot 2B-A               Added in pilot variation\n",
      "8   Pilot 2      Pilot 2D               Added in pilot variation\n",
      "9   Pilot 2    Pilot 2D-A  DO NOT USE: Manual Processing for now\n",
      "10  Pilot 3      Pilot 3A               Added in pilot variation\n",
      "11  Pilot 3    Pilot 3A-A  DO NOT USE: Manual Processing for now\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the pilot variation:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 10 for 'Pilot 3A'\n",
      "\n",
      "               Survey Filename\n",
      "0  Survey Pilot 1A and 1B.xlsx\n",
      "1          Survey Pilot 2.xlsx\n",
      "2    Survey Pilot 2 and 3.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the survey filename for your pilot run:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 2 for 'Survey Pilot 2 and 3.xlsx'\n",
      "\n",
      "Data processing completed.\n",
      "\n",
      "\n",
      "  Language\n",
      "0  Turkish\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the Language you are assessing:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 0 for Turkish\n",
      "\n",
      "Generating reports ...\n",
      "\n",
      "1. Language fail rates report completed and stored in reports > deliverables > Pilot 3 > Pilot 3A > Turkish\n",
      "\n",
      "2. Summary report completed and stored in analysis > Grand Summary > RC/V1/V2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    print('\\nData processing in progress...')\n",
    "    # import data from data_processing module\n",
    "    raters, r1, r2, r3, languages, rc, v1, v2, run_value , run_value_2, survey_selected, survey_files, pilot_variation, pilot_selected, pilot_var_selected = data_processing.main()\n",
    "    print('Data processing completed.')\n",
    "    print(\"\\n\")\n",
    "    print(languages)\n",
    "    \n",
    "    # Get input language selection\n",
    "    language_selected = language_selection(languages)\n",
    "      \n",
    "    # Get data from language modification processes\n",
    "    rcR, v1R, v2R = get_time_taken_all(language_selected, rc, v1, v2)\n",
    "    \n",
    "    print('\\nGenerating reports ...')\n",
    "    \n",
    "    # Start generating fail rate reports\n",
    "    list_of_datasets, list_of_summaries = generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Check the run type and language and create folders in reports > deliverables\n",
    "    run_folder, analysis_folder, folder_tag = file_check_create(root_path, config, language_selected, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Write reports to excel file in run_folder path\n",
    "    write_fail_report_to_excel(run_folder, list_of_datasets)\n",
    "    \n",
    "    print(f\"\\n1. Language fail rates report completed and stored in reports > deliverables > {run_value} > {pilot_var_selected} > {language_selected}\")\n",
    "    \n",
    "    # Write summaries to csv file in analysis_folder path\n",
    "    write_summary_to_excel(analysis_folder, list_of_summaries, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\n2. Summary report completed and stored in analysis > {folder_tag} > RC/V1/V2\")\n",
    "    \n",
    "    return r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 79)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 33)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pilot 3A'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_var_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 81)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 35)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Near Exact Match'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Close Match'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Reading Comprehension'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['RC with Answers'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019180</td>\n",
       "      <td>6</td>\n",
       "      <td>architectural</td>\n",
       "      <td>technical</td>\n",
       "      <td>çatı</td>\n",
       "      <td>architectural</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dam</td>\n",
       "      <td>hard</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019177</td>\n",
       "      <td>3</td>\n",
       "      <td>architectural</td>\n",
       "      <td>formal</td>\n",
       "      <td>konut</td>\n",
       "      <td>architectural</td>\n",
       "      <td>neutral</td>\n",
       "      <td>daire</td>\n",
       "      <td>hard</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019183</td>\n",
       "      <td>9</td>\n",
       "      <td>nature</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sahil</td>\n",
       "      <td>nature</td>\n",
       "      <td>neutral</td>\n",
       "      <td>plaj</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019185</td>\n",
       "      <td>11</td>\n",
       "      <td>Literature-cinema</td>\n",
       "      <td>technical</td>\n",
       "      <td>karakter</td>\n",
       "      <td>literature-cinema</td>\n",
       "      <td>technical</td>\n",
       "      <td>tip</td>\n",
       "      <td>hard</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019200</td>\n",
       "      <td>26</td>\n",
       "      <td>night life</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>fitil olmak</td>\n",
       "      <td>night life</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sarhoş olmak</td>\n",
       "      <td>hard</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Fluency    _unit_id  question_           a_domain      a_register  \\\n",
       "0  Turkish  Fluent  2914019180          6      architectural       technical   \n",
       "1  Turkish  Fluent  2914019177          3      architectural          formal   \n",
       "2  Turkish  Fluent  2914019183          9             nature         neutral   \n",
       "3  Turkish  Fluent  2914019185         11  Literature-cinema       technical   \n",
       "4  Turkish  Fluent  2914019200         26         night life  slang/informal   \n",
       "\n",
       "  wordphrase_a           b_domain b_register  wordphrase_b difficulty Answer  \\\n",
       "0         çatı      architectural    neutral           dam       hard     no   \n",
       "1        konut      architectural    neutral         daire       hard     no   \n",
       "2        sahil             nature    neutral          plaj     medium     no   \n",
       "3     karakter  literature-cinema  technical           tip       hard     no   \n",
       "4  fitil olmak         night life    neutral  sarhoş olmak       hard    yes   \n",
       "\n",
       "   Score  Count_of_Test_Takers  Total_Test_Takers  Fail_Rate  \n",
       "0      0                    20                 24       0.83  \n",
       "1      0                    17                 24       0.71  \n",
       "2      0                    14                 24       0.58  \n",
       "3      0                    11                 24       0.46  \n",
       "4      0                    10                 24       0.42  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Near Exact Match'].head() # v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Overall_Fail_Rate</th>\n",
       "      <th>Answers</th>\n",
       "      <th>a_and_b_are_not_related</th>\n",
       "      <th>a_and_b_are_related</th>\n",
       "      <th>a_and_b_have_the_same_meaning</th>\n",
       "      <th>a_is_more_specific_than_b</th>\n",
       "      <th>b_is_more_specific_than_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019221</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>formal</td>\n",
       "      <td>siyaset</td>\n",
       "      <td>politics</td>\n",
       "      <td>neutral</td>\n",
       "      <td>politika</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019225</td>\n",
       "      <td>6</td>\n",
       "      <td>clothes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>çarık</td>\n",
       "      <td>clothes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ayakkabı</td>\n",
       "      <td>medium</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019226</td>\n",
       "      <td>7</td>\n",
       "      <td>nature</td>\n",
       "      <td>formal</td>\n",
       "      <td>çınar</td>\n",
       "      <td>nature</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ağaç</td>\n",
       "      <td>hard</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019229</td>\n",
       "      <td>10</td>\n",
       "      <td>house items</td>\n",
       "      <td>neutral</td>\n",
       "      <td>kadeh</td>\n",
       "      <td>house items</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bardak</td>\n",
       "      <td>easy</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019233</td>\n",
       "      <td>14</td>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "      <td>pasta</td>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "      <td>makarna</td>\n",
       "      <td>easy</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>a_and_b_are_related;0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Fluency    _unit_id  question_     a_domain a_register  \\\n",
       "0  Turkish  Fluent  2914019221          2     politics     formal   \n",
       "1  Turkish  Fluent  2914019225          6      clothes    neutral   \n",
       "2  Turkish  Fluent  2914019226          7       nature     formal   \n",
       "3  Turkish  Fluent  2914019229         10  house items    neutral   \n",
       "4  Turkish  Fluent  2914019233         14         food    neutral   \n",
       "\n",
       "  wordphrase_a     b_domain b_register wordphrase_b difficulty  \\\n",
       "0      siyaset     politics    neutral     politika     medium   \n",
       "1        çarık      clothes    neutral     ayakkabı     medium   \n",
       "2        çınar       nature    neutral         ağaç       hard   \n",
       "3        kadeh  house items    neutral       bardak       easy   \n",
       "4        pasta         food    neutral      makarna       easy   \n",
       "\n",
       "   Count_of_Test_Takers  Total_Test_Takers  Overall_Fail_Rate  \\\n",
       "0                     1                 24               0.04   \n",
       "1                     6                 24               0.25   \n",
       "2                     1                 24               0.04   \n",
       "3                     6                 24               0.25   \n",
       "4                     6                 24               0.25   \n",
       "\n",
       "                           Answers  a_and_b_are_not_related  \\\n",
       "0  a_and_b_have_the_same_meaning;0                      NaN   \n",
       "1      a_is_more_specific_than_b;0                      NaN   \n",
       "2      a_is_more_specific_than_b;0                      NaN   \n",
       "3      a_is_more_specific_than_b;0                      NaN   \n",
       "4            a_and_b_are_related;0                     0.25   \n",
       "\n",
       "   a_and_b_are_related  a_and_b_have_the_same_meaning  \\\n",
       "0                 0.04                            NaN   \n",
       "1                 0.08                           0.17   \n",
       "2                  NaN                           0.04   \n",
       "3                 0.25                            NaN   \n",
       "4                  NaN                            NaN   \n",
       "\n",
       "   a_is_more_specific_than_b  b_is_more_specific_than_a  \n",
       "0                        NaN                        NaN  \n",
       "1                        NaN                        NaN  \n",
       "2                        NaN                        NaN  \n",
       "3                        NaN                        NaN  \n",
       "4                        NaN                        NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Close Match'].head() #v2_fail_rates or v2_actual_correct_by_question_with_answer for 1A-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>title</th>\n",
       "      <th>test_</th>\n",
       "      <th>Score</th>\n",
       "      <th>Question</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>register</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Count</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019342</td>\n",
       "      <td>Pandemi Sonrası Galatasaray'ın Durumu</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019338</td>\n",
       "      <td>Yapay Sinir Ağları</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 3</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019339</td>\n",
       "      <td>Tekila</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 3</td>\n",
       "      <td>hard</td>\n",
       "      <td>neutral</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019338</td>\n",
       "      <td>Yapay Sinir Ağları</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>easy</td>\n",
       "      <td>technical</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019339</td>\n",
       "      <td>Tekila</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>easy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Fluency    _unit_id                                  title  test_  \\\n",
       "0  Turkish  Fluent  2914019342  Pandemi Sonrası Galatasaray'ın Durumu      6   \n",
       "1  Turkish  Fluent  2914019338                     Yapay Sinir Ağları      2   \n",
       "2  Turkish  Fluent  2914019339                                 Tekila      3   \n",
       "3  Turkish  Fluent  2914019338                     Yapay Sinir Ağları      2   \n",
       "4  Turkish  Fluent  2914019339                                 Tekila      3   \n",
       "\n",
       "   Score    Question Difficulty   register  \\\n",
       "0      0  Question 1       easy   informal   \n",
       "1      0  Question 3       hard  technical   \n",
       "2      0  Question 3       hard    neutral   \n",
       "3      0  Question 1       easy  technical   \n",
       "4      0  Question 1       easy    neutral   \n",
       "\n",
       "                                        Skill  Count  Total  Fail_Rate  \n",
       "0  initial understanding: finding key details      7     24       0.29  \n",
       "1               synthesis and decision-making      4     24       0.17  \n",
       "2               synthesis and decision-making      4     24       0.17  \n",
       "3  initial understanding: finding key details      3     24       0.12  \n",
       "4  initial understanding: finding key details      3     24       0.12  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Reading Comprehension'].head() # rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>title</th>\n",
       "      <th>test_</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>register</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Question</th>\n",
       "      <th>Actual_Answer_Letter</th>\n",
       "      <th>Actual_Answer_Text</th>\n",
       "      <th>Rater_Answer_Letter</th>\n",
       "      <th>Rater_Answer_Text</th>\n",
       "      <th>Count</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019337</td>\n",
       "      <td>Ispanağı Nasıl Tüketmeli?</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>formal</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>c</td>\n",
       "      <td>İdeal hazırlama yöntemi ve pişirme süresine.\\n</td>\n",
       "      <td>b</td>\n",
       "      <td>İçindeki faydalı vitaminlere.</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019338</td>\n",
       "      <td>Yapay Sinir Ağları</td>\n",
       "      <td>2</td>\n",
       "      <td>easy</td>\n",
       "      <td>technical</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>a</td>\n",
       "      <td>YSA'lar insan beynini taklit ederek problemler...</td>\n",
       "      <td>b</td>\n",
       "      <td>YSA basit biyolojik sinir sistemidir.</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019338</td>\n",
       "      <td>Yapay Sinir Ağları</td>\n",
       "      <td>2</td>\n",
       "      <td>easy</td>\n",
       "      <td>technical</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>a</td>\n",
       "      <td>YSA'lar insan beynini taklit ederek problemler...</td>\n",
       "      <td>c</td>\n",
       "      <td>YSA'lar yaşayarak veya deneyerek öğrenir.</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019338</td>\n",
       "      <td>Yapay Sinir Ağları</td>\n",
       "      <td>2</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>Question 3</td>\n",
       "      <td>b</td>\n",
       "      <td>Yapay zeka</td>\n",
       "      <td>a</td>\n",
       "      <td>Biyoloji</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2914019339</td>\n",
       "      <td>Tekila</td>\n",
       "      <td>3</td>\n",
       "      <td>easy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>b</td>\n",
       "      <td>Avrupalılar ilk olarak tekilayı kıtalararası y...</td>\n",
       "      <td>a</td>\n",
       "      <td>Tekila agave denilen bir tür kaktüsten yapılma...</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Fluency    _unit_id                      title  test_ Difficulty  \\\n",
       "0  Turkish  Fluent  2914019337  Ispanağı Nasıl Tüketmeli?      1     medium   \n",
       "1  Turkish  Fluent  2914019338         Yapay Sinir Ağları      2       easy   \n",
       "2  Turkish  Fluent  2914019338         Yapay Sinir Ağları      2       easy   \n",
       "3  Turkish  Fluent  2914019338         Yapay Sinir Ağları      2       hard   \n",
       "4  Turkish  Fluent  2914019339                     Tekila      3       easy   \n",
       "\n",
       "    register                                         Skill    Question  \\\n",
       "0     formal  initial understanding: finding the main idea  Question 2   \n",
       "1  technical    initial understanding: finding key details  Question 1   \n",
       "2  technical    initial understanding: finding key details  Question 1   \n",
       "3  technical                 synthesis and decision-making  Question 3   \n",
       "4    neutral    initial understanding: finding key details  Question 1   \n",
       "\n",
       "  Actual_Answer_Letter                                 Actual_Answer_Text  \\\n",
       "0                    c     İdeal hazırlama yöntemi ve pişirme süresine.\\n   \n",
       "1                    a  YSA'lar insan beynini taklit ederek problemler...   \n",
       "2                    a  YSA'lar insan beynini taklit ederek problemler...   \n",
       "3                    b                                         Yapay zeka   \n",
       "4                    b  Avrupalılar ilk olarak tekilayı kıtalararası y...   \n",
       "\n",
       "  Rater_Answer_Letter                                  Rater_Answer_Text  \\\n",
       "0                   b                      İçindeki faydalı vitaminlere.   \n",
       "1                   b              YSA basit biyolojik sinir sistemidir.   \n",
       "2                   c          YSA'lar yaşayarak veya deneyerek öğrenir.   \n",
       "3                   a                                           Biyoloji   \n",
       "4                   a  Tekila agave denilen bir tür kaktüsten yapılma...   \n",
       "\n",
       "   Count  Total  Fail_Rate  \n",
       "0      1     24       0.04  \n",
       "1      2     24       0.08  \n",
       "2      1     24       0.04  \n",
       "3      4     24       0.17  \n",
       "4      3     24       0.12  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['RC with Answers'].head() # rc_question_skill_pass_rate_answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store all 4 reports into a dictionary set\n",
    "# list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "#                     \"Close Match\" : v2_fail_rates,\n",
    "#                     \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "#                     \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ------------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def v2_fail_rate_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "#     vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "#     # first grouping\n",
    "#     vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "#     vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "#     # second grouping\n",
    "#     vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "#     vR_grouped['Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "#     # filter Score 0 . Note Pilot 1C,1D seem to have this disabled, but it's not making sense as Fail Rate should have Score = 0.\n",
    "#     if pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D':\n",
    "#         vR_grouped = vR_grouped\n",
    "        \n",
    "#     elif pilot_var_selected == 'Pilot 3A':\n",
    "#         vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "#     # sort values by Market and _unit_id \n",
    "#     vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "#     # drop Score columns\n",
    "#     vR_grouped = vR_grouped.drop(selector_2['drop_cols'], axis = 1)\n",
    "    \n",
    "#     vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "     \n",
    "#     vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].fillna('Null')\n",
    "    \n",
    "#     vR_fail_rates  = pd.pivot_table(vR_fail_rates, \n",
    "#                            index = selector_2['explode'],\n",
    "#                            values='Rate', columns=['rater_answer']).reset_index()\n",
    "#     vR_fail_rates.columns.name = None # remove name for columns\n",
    "    \n",
    "#     vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].replace('Null', np.nan)\n",
    "    \n",
    "#     # remove duplicate rows in the dataframe\n",
    "#     vR_fail_rates = vR_fail_rates.drop_duplicates()\n",
    "    \n",
    "#     return vR_fail_rates #vR_fail_rates \n",
    "\n",
    "# def generate_report_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "#     v2_actual_correct_by_question = v2_fail_rate(v2R, selector_2)\n",
    "\n",
    "#     v2_actual_correct_by_question_with_answer = v2_fail_rate_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "#     v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2)\n",
    "    \n",
    "#     return v2_fail_rates, v2_actual_correct_by_question,  v2_actual_correct_by_question_with_answer\n",
    "\n",
    "# raters, r1, r2, r3, languages, rc, v1, v2, run_value , run_value_2, survey_selected, survey_files, pilot_variation, pilot_selected, pilot_var_selected = data_processing.main()\n",
    "\n",
    "# # Get data from language modification processes\n",
    "# rcR, v1R, v2R = get_time_taken_all('Japanese', rc, v1, v2)\n",
    "\n",
    "# selector_2 = report_2_selector('Pilot 2B-A')\n",
    "# #vR_fail_rates = v2_fail_rate_2(v2R, selector_2, 'Pilot 1E')\n",
    "# v2_fail_rates, v2_actual_correct_by_question,  v2_actual_correct_by_question_with_answer = generate_report_2(v2R, selector_2, 'Pilot 2B-A')\n",
    "# v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2)\n",
    "# v2_fail_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def generate_report_3(rcR, selector_3):\n",
    "    \n",
    "# #     rc_answer = rc_fail_rate(rcR, selector_3)\n",
    "    \n",
    "# # #     rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "# # #     rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "# # #     rc_question_skill_pass_rate = rc_q_s_pass_rate(rc_answer, selector_3)\n",
    "    \n",
    "# #     return  rc_answer # rc_question_skill_pass_rate\n",
    "\n",
    "\n",
    "# def rc_fail_rate(rcR, selector_3):\n",
    "\n",
    "#     vR_temp = rcR[selector_3['select1']]\n",
    "     \n",
    "#     cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "#     cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "#     vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "#     cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "#     cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "#     vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "#     cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "#     cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "#     vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "#     cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "#     cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "#     vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "#     # Dropping columns\n",
    "#     vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "#     # concatenate values from different columns with delimiter ;\n",
    "#     vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "#     vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "#     vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "#                                      'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "#     vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "#                                                  'question_2_google_translate_error', \n",
    "#                                                  'question_3_google_translate_error', \n",
    "#                                                  'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "#     vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "#                                 'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "#     # Dropping more columns\n",
    "#     vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "#     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "#     vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "#     vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "#                                                                                                'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "#     vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "#     vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "#     rc_answer = vR_temp\n",
    "    \n",
    "#     return rc_answer\n",
    "\n",
    "# selector_3 = report_3_selector('Pilot 1E')\n",
    "\n",
    "# output = rc_fail_rate(rcR, selector_3)\n",
    "# output\n",
    "# #output[['question_no_1', 'Answer_no_1', 'question_no_2', 'Answer_no_2', 'question_no_3', 'Answer_no_3', 'question_no_4', 'Answer_no_4', 'a1', 'a2', 'a3', 'a4']].tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ---------------------------------------------------------------\n",
    "\n",
    "# def v1_fail_rate(v1R, selector_1):  #Valid for Pilot 3A, 1C\n",
    "    \n",
    "#     vR_temp = v1R[selector_1['select1']]\n",
    "    \n",
    "#     # first grouping\n",
    "#     vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "#     vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "# #     # second grouping\n",
    "# #     vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "# #     vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "# #     # filter Score 0\n",
    "# #     vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "# #     # sort values by Market and Fail_rate descending \n",
    "# #     vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending = selector_1['sort_order'])\n",
    "    \n",
    "# #     vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "#     return vR_grouped #vR_fail_rates\n",
    "\n",
    "# def generate_report_1(v1R, selector_1):\n",
    "    \n",
    "#     v1_actual_correct_by_question = v1_fail_rate(v1R, selector_1)\n",
    "    \n",
    "#     return v1_actual_correct_by_question\n",
    "\n",
    "# selector_1 = report_1_selector('Pilot 1E')\n",
    "# output = v1_fail_rate(v1R, selector_1)\n",
    "# output.to_excel('TEMP.xlsx', index=False, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
