{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################       \n",
    "#Script Name    :                                                                                              \n",
    "#Description    :                                                                                 \n",
    "#Args           :                                                                                           \n",
    "#Author         : Nikhil Rao in R, converted to Python by Nor Raymond                                              \n",
    "#Email          : nraymond@appen.com                                          \n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "except:\n",
    "    \n",
    "    os.chdir('..')\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to initialize data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize data ingestion and file checking...\n"
     ]
    }
   ],
   "source": [
    "def group_files_by_language(data_path, files, file_initials):\n",
    "    \n",
    "    file_groups = {}  \n",
    "    for x in files:  \n",
    "        key = x.split('_')[0] #x[:16] # The key is the first 16 characters of the file name\n",
    "        group = file_groups.get(key,[])\n",
    "        group.append(x)  \n",
    "        file_groups[key] = group\n",
    "                \n",
    "    return file_groups\n",
    "\n",
    "def create_file_exists_df(files, file_initials):\n",
    "    \n",
    "    checker = []\n",
    "    file_exists = []\n",
    "    for fname in files:\n",
    "        for key in file_initials:\n",
    "            if key in fname:\n",
    "                file_exists.append((key, fname))\n",
    "\n",
    "    file_exists = pd.DataFrame(file_exists, columns =['Keyword', 'Filename'])\n",
    "    \n",
    "    return file_exists\n",
    "\n",
    "def data_ingestion_initialize(root_path):\n",
    "    \n",
    "    # Function to load yaml configuration file\n",
    "    def load_config(config_name):\n",
    "        with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "\n",
    "        return config\n",
    "\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    print(\"Initialize data ingestion and file checking...\")\n",
    "    \n",
    "    # define data input paths\n",
    "    data_path = os.path.join(root_path, config[\"data_path\"][\"output\"])\n",
    "       \n",
    "    # get the list of files in raw folder\n",
    "    files = os.listdir(data_path)\n",
    "    files = [f for f in files if f[-5:] == '.xlsx']\n",
    "    \n",
    "    file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "\n",
    "    languages = []\n",
    "    for file in files:\n",
    "        for file_initial in file_initials:        \n",
    "            lang = file.split('_' + file_initial)[0]\n",
    "        if not lang.endswith((\".xlsx\")):\n",
    "            languages.append(lang)\n",
    "    \n",
    "    languages = pd.DataFrame(languages, columns = ['Language'])\n",
    "    \n",
    "    file_groups = group_files_by_language(data_path, files, file_initials)\n",
    "    \n",
    "    file_exists = create_file_exists_df(files, file_initials)\n",
    "    \n",
    "    return data_path, files, languages, file_groups, file_exists\n",
    "       \n",
    "data_path, files, languages, file_groups, file_exists = data_ingestion_initialize(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "\n",
    "def obtain_file_summary_df(file_initials):\n",
    "    \n",
    "    df_summary = []\n",
    "    for k in file_initials:\n",
    "        selected_files = file_exists[file_exists['Keyword'] == k] \n",
    "        selected_filenames = selected_files['Filename'].tolist()\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for f in selected_filenames:\n",
    "            data = pd.read_excel(os.path.join(data_path, f), 'Summary')\n",
    "            df = df.append(data)\n",
    "\n",
    "        df_summary.append(df)    \n",
    "        \n",
    "    return df_summary\n",
    "\n",
    "def obtain_file_data_df(file_initials):\n",
    "    \n",
    "    df_data = []\n",
    "    for k in file_initials:\n",
    "        selected_files = file_exists[file_exists['Keyword'] == k] \n",
    "        selected_filenames = selected_files['Filename'].tolist()\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for f in selected_filenames:\n",
    "            data = pd.read_excel(os.path.join(data_path, f), 'Data')\n",
    "            df = df.append(data)\n",
    "\n",
    "        df_data.append(df)    \n",
    "        \n",
    "    return df_data\n",
    "\n",
    "def obtain_distinct_raters(df_summary):\n",
    "\n",
    "    r1 = df_summary[0] # Joined data for Summary sheet from RC \n",
    "    r2 = df_summary[1] # Joined data for Summary page from Vocab_1 \n",
    "    r3 = df_summary[2] # Joined data for Summary page from Vocab_2 \n",
    "    \n",
    "    raters = pd.concat([r1,r2,r3], ignore_index=True)\n",
    "    raters = raters[['_worker_id', 'Grouping', 'Market', 'Language']]\n",
    "    raters = raters.drop_duplicates()\n",
    "    \n",
    "    # obtain languages from r1 and create a dataframe\n",
    "    languages = r1.Language.unique().tolist()\n",
    "    languages = pd.DataFrame(languages, columns = ['Language'])\n",
    "    \n",
    "    return raters, r1, r2, r3, languages\n",
    "\n",
    "def merge_raters_to_df_data(df_data, raters):\n",
    "\n",
    "    rc = df_data[0] # Joined data for Data sheet from RC \n",
    "    v1 = df_data[1] # Joined data for Data page from Vocab_1 \n",
    "    v2 = df_data[2] # Joined data for Data page from Vocab_2 \n",
    "    \n",
    "    # Merge raters to v1, v2, and rc\n",
    "    rc = pd.merge(rc, raters,  how='left', on=['_worker_id', 'Language'])\n",
    "    v1 = pd.merge(v1, raters,  how='left', on=['_worker_id', 'Language'])\n",
    "    v2 = pd.merge(v2, raters,  how='left', on=['_worker_id', 'Language'])\n",
    "    \n",
    "    # Convert _created_at and _started_at to date-time\n",
    "    rc[['_created_at','_started_at']] = rc[['_created_at','_started_at']].apply(pd.to_datetime, format='%m/%d/%Y %H:%M:%S')\n",
    "    v1[['_created_at','_started_at']] = v1[['_created_at','_started_at']].apply(pd.to_datetime, format='%m/%d/%Y %H:%M:%S')\n",
    "    v2[['_created_at','_started_at']] = v2[['_created_at','_started_at']].apply(pd.to_datetime, format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    return rc, v1, v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated data processing completed.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "\n",
    "    df_summary = obtain_file_summary_df(file_initials)\n",
    "    df_data = obtain_file_data_df(file_initials)\n",
    "    raters, r1, r2, r3, languages =  obtain_distinct_raters(df_summary)\n",
    "    rc, v1, v2 = merge_raters_to_df_data(df_data, raters)\n",
    "    \n",
    "    return raters, r1, r2, r3, languages, rc, v1, v2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    raters, r1, r2, r3, languages, rc, v1, v2 = main()\n",
    "    print('Automated data processing completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language\n",
       "0     Russian\n",
       "1      Hebrew\n",
       "2  Indonesian"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Market</th>\n",
       "      <th>_worker_id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Grouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russian</td>\n",
       "      <td>RU-RU</td>\n",
       "      <td>29763429</td>\n",
       "      <td>11</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Pilot 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russian</td>\n",
       "      <td>RU-RU</td>\n",
       "      <td>45671891</td>\n",
       "      <td>11</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Pilot 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>RU-RU</td>\n",
       "      <td>45671901</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Pilot 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russian</td>\n",
       "      <td>RU-RU</td>\n",
       "      <td>45671918</td>\n",
       "      <td>7</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Pilot 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russian</td>\n",
       "      <td>RU-RU</td>\n",
       "      <td>45671928</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Pilot 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Market  _worker_id  Score  Percentage Grouping\n",
       "0  Russian  RU-RU    29763429     11    0.916667  Pilot 2\n",
       "1  Russian  RU-RU    45671891     11    0.916667  Pilot 2\n",
       "2  Russian  RU-RU    45671901      9    0.750000  Pilot 2\n",
       "3  Russian  RU-RU    45671918      7    0.583333  Pilot 2\n",
       "4  Russian  RU-RU    45671928     10    0.833333  Pilot 2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
