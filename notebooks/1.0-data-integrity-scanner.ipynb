{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################       \n",
    "#Script Name    :                                                                                              \n",
    "#Description    :                                                                                 \n",
    "#Args           :                                                                                           \n",
    "#Author         : Nor Raymond                                                \n",
    "#Email          : nraymond@appen.com                                          \n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "\n",
    "try:\n",
    "\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "\n",
    "except:\n",
    "\n",
    "    os.chdir('..')\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_ingestion import data_ingestion_initialize, raw_file_checker, create_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data integrity scanning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def print_scan_results(col_condition_num, scan_num, file_initial , sheets = 'Summary'):\n",
    "    \n",
    "    if scan_num == 1:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if the sheet contains either 'Language' and 'Market' columns ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Summary' sheet contains both 'Language' and 'Market' columns\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Summary' sheet does not contain either 'Language' and 'Market' columns\")\n",
    "\n",
    "    if scan_num == 2:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if Language' and 'Market' columns are empty ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": Both 'Language' and 'Market' columns in 'Summary' contains complete data\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": Both or either 'Language' and 'Market' columns in 'Summary' sheet are empty or incomplete\")\n",
    "            \n",
    "    if scan_num == 3 or scan_num == 6:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if '_worker_id' column name is correct ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": valid '_workder_id' column name\")\n",
    "        else:\n",
    "            print(color.RED + \"FAIL\" + color.END + \": invalid '_workder_id' column name\")\n",
    "            \n",
    "    if scan_num == 4:         \n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if sheet contains 'Language' column ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Data' sheet contains 'Language' columns\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Data' sheet does not contain 'Language' columns\")\n",
    "            \n",
    "    if scan_num == 5:         \n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if Language' column are empty ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Language'column in 'Data' contains complete data\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Language' column in 'Data' sheet are empty or incomplete\")\n",
    "            \n",
    "    if scan_num == 7 and file_initial == 'RC':         \n",
    "        print(f\"\\nSCAN-7 : {file_initial} - {sheets} : checking if columns in the 'Data' sheet are identical to the reference columns ...\")\n",
    "        if col_condition_num == True:\n",
    "            print (color.GREEN + \"PASS\" + color.END + \": The columns in the 'Data' sheet are identical to the reference\") \n",
    "        else: \n",
    "            print (color.RED + \"FAIL\" + color.END + \": The columns in the 'Data' sheet are not identical to the reference\")         \n",
    "            \n",
    "def summary_col_check(df_summary, df_summary_cols, file_initial , sheets = 'Summary'): \n",
    "      \n",
    "    # --- SCAN-1 : checking if \"Summary\" sheet contains \"Language\" and \"Market\" columns   ---------------------\n",
    "    # PASS -> 'Summary' sheet contains both 'Language' and 'Market' columns\n",
    "    scan_num = 1\n",
    "    cols_to_check = ['Language', 'Market']\n",
    "    col_checker = {}   \n",
    "    for col in cols_to_check:\n",
    "        \n",
    "        if col in df_summary_cols:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "            \n",
    "    condition_1 = col_checker['Language']\n",
    "    condition_2 = col_checker['Market']\n",
    "    col_condition_1 = all([condition_1, condition_2]) # both conditions has to be true\n",
    "\n",
    "    return col_condition_1, scan_num\n",
    "\n",
    "def summary_col_value_check(df_summary, file_initial, sheets = 'Summary'): \n",
    "    \n",
    "    # --- SCAN-2 :checking if \"Language\" and \"Market\" columns in \"Summary\" is empty   -------------------------\n",
    "    # PASS -> Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
    "    scan_num = 2\n",
    "    cols_to_check = ['Language', 'Market']\n",
    "    col_checker = {}\n",
    "    for col in cols_to_check:\n",
    "\n",
    "        if df_summary[col].notnull().values.all() == True:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "\n",
    "    condition_3 = col_checker['Language']\n",
    "    condition_4 = col_checker['Market']\n",
    "    col_condition_2 = all([condition_3, condition_4]) # both conditions has to be true\n",
    "\n",
    "    return col_condition_2, scan_num\n",
    "\n",
    "def col_header_check(df_summary_data, file_initial, sheets):\n",
    "    \n",
    "    # --- SCAN-3 : checking if worker_id column contains _ at the start   -------------------------------------\n",
    "    # PASS -> if the number of character is 10 not 9 and column name is _workder_id\n",
    "    scan_num = 3\n",
    "    find_worker_idx = df_summary_data.columns.str.contains('worker')\n",
    "    worker_idx = [i for i, x in enumerate(find_worker_idx) if x][0]\n",
    "    worker_col = df_summary_data.columns[worker_idx]\n",
    "    worker_col_len = len(worker_col)\n",
    "    \n",
    "    if worker_col_len == 10 and worker_col[0] == \"_\":\n",
    "        col_condition_3 = True\n",
    "    elif worker_col_len == 9 and worker_col[0] == \"w\":\n",
    "        col_condition_3 = False\n",
    "    return col_condition_3, scan_num\n",
    "\n",
    "def data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data'): \n",
    "      \n",
    "    # --- SCAN-4 : checking if \"Data\" sheet contains \"Language\" column   --------------------------------------\n",
    "    # PASS -> 'Data' sheet contains both 'Language' column\n",
    "    scan_num = 4\n",
    "    cols_to_check = ['Language']\n",
    "    col_checker = {}   \n",
    "    for col in cols_to_check:\n",
    "        \n",
    "        if col in df_data_cols:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "            \n",
    "    condition_1 = col_checker['Language']\n",
    "    col_condition_4 = all([condition_1])\n",
    "        \n",
    "    return col_condition_4, scan_num\n",
    "\n",
    "def data_col_value_check(df_data, file_initial, sheets = 'Data'): \n",
    "    \n",
    "    # --- SCAN-5 :checking if \"Language\" column in \"Data\" is empty   -------------------------\n",
    "    # PASS -> 'Language' column in 'Data' contains complete data\n",
    "    scan_num = 5\n",
    "    cols_to_check = ['Language']\n",
    "    col_checker = {}\n",
    "    for col in cols_to_check:\n",
    "\n",
    "        if df_data[col].notnull().values.all() == True:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "\n",
    "    condition_3 = col_checker['Language']\n",
    "    col_condition_5 = all([condition_3])\n",
    "\n",
    "    return col_condition_5, scan_num\n",
    "\n",
    "def data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data'):\n",
    "    \n",
    "    # --- SCAN-7 : checking if columns in \"Data\" sheet are identical to the reference columns   ------------------------\n",
    "    # refer to the file in reference > reference_checks.xlsx\n",
    "    # PASS -> if the two column lists are identical\n",
    "    scan_num = 7\n",
    "    ref_data_cols_sorted = ref_data_cols\n",
    "    df_data_cols_sorted = df_data_cols\n",
    "    \n",
    "    # sorting both the lists \n",
    "    ref_data_cols_sorted.sort() \n",
    "    df_data_cols_sorted.sort() \n",
    "    \n",
    "    # using == to check if  \n",
    "    if ref_data_cols_sorted == df_data_cols_sorted:\n",
    "        col_condition_7 = True\n",
    "    else : \n",
    "        col_condition_7 = False\n",
    "    return col_condition_7, scan_num\n",
    "\n",
    "def data_integrity_check(df_summary, df_summary_cols, df_data, df_data_cols, file_initial, ref_data_cols): \n",
    "    \n",
    "    print(color.BOLD + f\"Reading {file_initial} raw data and perform data integrity scanning...:\\n\" + color.END)\n",
    "      \n",
    "    conditions_list = []\n",
    "    \n",
    "    # SCAN-1\n",
    "    col_condition_1, scan_num = summary_col_check(df_summary, df_summary_cols, file_initial , 'Summary')\n",
    "    print_scan_results(col_condition_1, scan_num, file_initial , sheets = 'Summary')\n",
    "    conditions_list.append(col_condition_1)\n",
    "      \n",
    "    # SCAN-2\n",
    "    # Runs only when col_condition_1 returns True\n",
    "    if col_condition_1 == True:\n",
    "        col_condition_2, scan_num = summary_col_value_check(df_summary, file_initial, 'Summary')  \n",
    "        print_scan_results(col_condition_2, scan_num, file_initial , sheets = 'Summary')\n",
    "        conditions_list.append(col_condition_2)\n",
    "    else:\n",
    "        conditions_list = conditions_list\n",
    "\n",
    "    # SCAN-3\n",
    "    col_condition_3, scan_num = col_header_check(df_summary, file_initial, 'Summary')\n",
    "    print_scan_results(col_condition_3, scan_num, file_initial , sheets = 'Summary')\n",
    "    conditions_list.append(col_condition_3)\n",
    "    \n",
    "    # SCAN-4\n",
    "    col_condition_4, scan_num = data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data')\n",
    "    print_scan_results(col_condition_4, scan_num, file_initial , sheets = 'Data')\n",
    "    conditions_list.append(col_condition_4)\n",
    "    \n",
    "    # SCAN-5\n",
    "    # Runs only when col_condition_4 returns True\n",
    "    if col_condition_4 == True:\n",
    "        col_condition_5, scan_num = data_col_value_check(df_data, file_initial, sheets = 'Data')\n",
    "        print_scan_results(col_condition_5, scan_num, file_initial , sheets = 'Data')\n",
    "        conditions_list.append(col_condition_5)\n",
    "    else:\n",
    "        conditions_list = conditions_list\n",
    "        \n",
    "    # SCAN-6 \n",
    "    col_condition_6, scan_num = col_header_check(df_data, file_initial, 'Data')\n",
    "    scan_num = 6\n",
    "    print_scan_results(col_condition_6, scan_num, file_initial , 'Data')\n",
    "    conditions_list.append(col_condition_6)\n",
    "    \n",
    "    # SCAN-7\n",
    "    if file_initial == 'RC':\n",
    "        col_condition_7, scan_num = data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data')\n",
    "        print_scan_results(col_condition_7, scan_num, file_initial , 'Data')\n",
    "        conditions_list.append(col_condition_7)\n",
    "       \n",
    "    # Final data integrity results after all checks\n",
    "    # PASS -> when all scans return True/PASS\n",
    "    if len(conditions_list) > 1 :\n",
    "        integrity_result = all(conditions_list)\n",
    "        if integrity_result == True:\n",
    "            print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.GREEN + ' PASS' + color.END + '\\n')\n",
    "        else: \n",
    "            print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.RED + ' FAIL' + color.END + '\\n')\n",
    "    elif len(conditions_list) == 1: \n",
    "        print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.RED + ' FAIL' + color.END + '\\n')\n",
    "\n",
    "    return integrity_result, conditions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the data integrity report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize data ingestion and file checking...\n",
      "PASS: All files exists!\n",
      "Dataframe created from RC file\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Summary' sheet does not contain either 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[91mFAIL\u001b[0m: invalid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Data' sheet does not contain 'Language' columns\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[91mFAIL\u001b[0m: The columns in the 'Data' sheet are not identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[91m FAIL\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Summary' sheet does not contain either 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[91mFAIL\u001b[0m: invalid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Data' sheet does not contain 'Language' columns\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[91m FAIL\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Summary' sheet does not contain either 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[91mFAIL\u001b[0m: 'Data' sheet does not contain 'Language' columns\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[91m FAIL\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  \n",
    "    # initialize data ingestion and obtain the data catalog dictionary (all variables)\n",
    "    print(\"Initialize data ingestion and file checking...\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "\n",
    "        data_catalog = data_ingestion_initialize(root_path, config_path)\n",
    "\n",
    "        raw_data_path = data_catalog[\"raw_data_path\"]\n",
    "        out_data_path = data_catalog[\"out_data_path\"]\n",
    "        ref_path = data_catalog[\"ref_path\"]\n",
    "        ref_filepath = data_catalog[\"ref_filepath\"]\n",
    "        ref_data = data_catalog[\"ref_data\"]\n",
    "        ref_data_cols = data_catalog[\"ref_data_cols\"]\n",
    "        files = data_catalog[\"files\"]\n",
    "        file_exists = data_catalog[\"file_exists\"]\n",
    "        rc_filepath = data_catalog[\"rc_filepath\"]\n",
    "        v1_filepath = data_catalog[\"v1_filepath\"]\n",
    "        v2_filepath = data_catalog[\"v2_filepath\"]\n",
    "        condition = data_catalog[\"condition\"]\n",
    "        file_exists = data_catalog[\"file_exists\"]\n",
    "        message = data_catalog[\"message\"]\n",
    "        print(message)\n",
    "\n",
    "        int_results = {}\n",
    "        for file_initial in file_initials:\n",
    "            df_catalog = create_dataframes(file_initial, rc_filepath, v1_filepath , v2_filepath) \n",
    "\n",
    "            # turn df_catalog into variables\n",
    "\n",
    "            df_summary = df_catalog[\"df_summary\"]\n",
    "            df_summary_cols = df_catalog[\"df_summary_cols\"] \n",
    "            df_data = df_catalog[\"df_data\"]\n",
    "            df_data_cols = df_catalog[\"df_data_cols\"] \n",
    "\n",
    "            integrity_result, conditions_list = data_integrity_check(df_summary, df_summary_cols, df_data, df_data_cols, file_initial, ref_data_cols)\n",
    "            int_results[file_initial] = integrity_result\n",
    "        \n",
    "    except: \n",
    "        data_catalog = data_ingestion_initialize(root_path, config_path)\n",
    "        message = data_catalog[\"message\"]\n",
    "        condition = data_catalog[\"condition\"]\n",
    "        print(message)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
