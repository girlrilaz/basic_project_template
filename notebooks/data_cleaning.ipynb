{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "# load yaml catalog configuration file\n",
    "config = load_config(\"catalog.yml\")\n",
    "\n",
    "os.chdir(config[\"project_path\"])\n",
    "root_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to initialize data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize data ingestion and file checking...\n",
      "PASS: All files exists!\n"
     ]
    }
   ],
   "source": [
    "def raw_file_checker(files): \n",
    "\n",
    "    keyword = ['RC', 'Vocab_2', 'Vocab_1']\n",
    "    checker = []\n",
    "    file_exists = {}\n",
    "    for fname in files:\n",
    "        for key in keyword:\n",
    "            if key in fname:\n",
    "                checker.append(True)\n",
    "                file_exists[key] = os.path.join(fname)\n",
    "                \n",
    "    if len(checker) == 3 :\n",
    "        print(\"PASS: All files exists!\")\n",
    "        condition = True\n",
    "    else:\n",
    "        print(\"FAIL: Not all file exists! Please check the raw data folder to ensure RC, Vocab_1 and Vocab_2 file exists.\")\n",
    "        condition = False\n",
    "        \n",
    "    return condition, file_exists\n",
    "\n",
    "\n",
    "def data_ingestion_initialize(root_path):\n",
    "    \n",
    "    # Function to load yaml configuration file\n",
    "    def load_config(config_name):\n",
    "        with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "\n",
    "        return config\n",
    "\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    print(\"Initialize data ingestion and file checking...\")\n",
    "    \n",
    "    # define input and output data paths\n",
    "    raw_data_path = os.path.join(root_path, config[\"data_path\"][\"input\"])\n",
    "    out_data_path = os.path.join(root_path, config[\"data_path\"][\"output\"])\n",
    "    \n",
    "    # define reference file paths\n",
    "    ref_path = os.path.join(root_path, config[\"data_path\"][\"ref\"])\n",
    "    ref_filepath = os.path.join(ref_path, config[\"filenames\"][\"rc_col_ref\"])\n",
    "    ref_data = pd.read_excel(io = ref_filepath, sheet_name=\"columns_check\", header=None)\n",
    "    ref_data_cols = ref_data[0].tolist()\n",
    "    \n",
    "    # get the list of files in raw folder\n",
    "    files = os.listdir(raw_data_path)\n",
    "    files = [f for f in files if f[-4:] == '.xls']\n",
    "    \n",
    "    condition, file_exists = raw_file_checker(files)\n",
    "    \n",
    "    ## Define raw data filepaths\n",
    "    rc_filepath = os.path.join(raw_data_path, file_exists['RC'])\n",
    "    v1_filepath = os.path.join(raw_data_path, file_exists['Vocab_1'])\n",
    "    v2_filepath = os.path.join(raw_data_path, file_exists['Vocab_2'])\n",
    "       \n",
    "    return raw_data_path, out_data_path, ref_path, ref_filepath, ref_data, ref_data_cols, files, file_exists, rc_filepath, v1_filepath, v2_filepath\n",
    "\n",
    "raw_data_path, out_data_path, ref_path, ref_filepath, ref_data, ref_data_cols, files, file_exists, rc_filepath, v1_filepath, v2_filepath = data_ingestion_initialize(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframes(file_initial, rc_filepath, v1_filepath , v2_filepath):\n",
    "    \n",
    "    '''\n",
    "    file_initial choices -\n",
    "    RC: Reading Comprehension \n",
    "    Vocab_1: Vocabulary 1 \n",
    "    Vocab_2: Vocabulary 2\n",
    "    '''\n",
    "    \n",
    "    if file_initial == 'RC':\n",
    "        filepath = rc_filepath\n",
    "    elif file_initial == 'Vocab_1':\n",
    "        filepath = v1_filepath\n",
    "    elif file_initial == 'Vocab_2':\n",
    "        filepath = v2_filepath\n",
    "    \n",
    "    # create dataframe from 'Summary' sheet\n",
    "    df_summary = pd.read_excel(io = filepath, sheet_name=\"Summary\")\n",
    "    df_summary_cols = list(df_summary.columns)\n",
    "    \n",
    "    # create dataframe from 'Data' sheet\n",
    "    df_data = pd.read_excel(io=filepath, sheet_name=\"Data\")\n",
    "    df_data_cols = list(df_data.columns)\n",
    "    \n",
    "    # create dataframe from 'Data' sheet\n",
    "    df_ans_key = pd.read_excel(io=filepath, sheet_name=\"Answer Key\")\n",
    "    df_ans_key_cols = list(df_ans_key.columns)\n",
    "    \n",
    "    print(f\"Dataframe created from {file_initial} file\")\n",
    "    \n",
    "    return df_summary, df_summary_cols, df_data, df_data_cols, df_ans_key, df_ans_key_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data integrity scanning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def print_scan_results(col_condition_num, scan_num, file_initial , sheets = 'Summary'):\n",
    "    \n",
    "    if scan_num == 1:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if the sheet contains either 'Language' and 'Market' columns ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Summary' sheet contains both 'Language' and 'Market' columns\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Summary' sheet does not contain either 'Language' and 'Market' columns\")\n",
    "\n",
    "    if scan_num == 2:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if Language' and 'Market' columns are empty ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": Both 'Language' and 'Market' columns in 'Summary' contains complete data\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": Both or either 'Language' and 'Market' columns in 'Summary' sheet are empty or incomplete\")\n",
    "            \n",
    "    if scan_num == 3 or scan_num == 6:\n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if '_worker_id' column name is correct ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": valid '_workder_id' column name\")\n",
    "        else:\n",
    "            print(color.RED + \"FAIL\" + color.END + \": invalid '_workder_id' column name\")\n",
    "            \n",
    "    if scan_num == 4:         \n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if sheet contains 'Language' column ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Data' sheet contains 'Language' columns\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Data' sheet does not contain 'Language' columns\")\n",
    "            \n",
    "    if scan_num == 5:         \n",
    "        print(f\"\\nSCAN-{scan_num} : {file_initial} - {sheets} : Checking if Language' column are empty ...\")\n",
    "        if col_condition_num == True:\n",
    "            print(color.GREEN + \"PASS\" + color.END + \": 'Language'column in 'Data' contains complete data\")\n",
    "        else: \n",
    "            print(color.RED + \"FAIL\" + color.END + \": 'Language' column in 'Data' sheet are empty or incomplete\")\n",
    "            \n",
    "    if scan_num == 7 and file_initial == 'RC':         \n",
    "        print(f\"\\nSCAN-7 : {file_initial} - {sheets} : checking if columns in the 'Data' sheet are identical to the reference columns ...\")\n",
    "        if col_condition_num == True:\n",
    "            print (color.GREEN + \"PASS\" + color.END + \": The columns in the 'Data' sheet are identical to the reference\") \n",
    "        else: \n",
    "            print (color.RED + \"FAIL\" + color.END + \": The columns in the 'Data' sheet are not identical to the reference\")         \n",
    "            \n",
    "def summary_col_check(df_summary, df_summary_cols, file_initial , sheets = 'Summary'): \n",
    "      \n",
    "    # --- SCAN-1 : checking if \"Summary\" sheet contains \"Language\" and \"Market\" columns   ---------------------\n",
    "    # PASS -> 'Summary' sheet contains both 'Language' and 'Market' columns\n",
    "    scan_num = 1\n",
    "    cols_to_check = ['Language', 'Market']\n",
    "    col_checker = {}   \n",
    "    for col in cols_to_check:\n",
    "        \n",
    "        if col in df_summary_cols:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "            \n",
    "    condition_1 = col_checker['Language']\n",
    "    condition_2 = col_checker['Market']\n",
    "    col_condition_1 = all([condition_1, condition_2]) # both conditions has to be true\n",
    "\n",
    "    return col_condition_1, scan_num\n",
    "\n",
    "def summary_col_value_check(df_summary, file_initial, sheets = 'Summary'): \n",
    "    \n",
    "    # --- SCAN-2 :checking if \"Language\" and \"Market\" columns in \"Summary\" is empty   -------------------------\n",
    "    # PASS -> Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
    "    scan_num = 2\n",
    "    cols_to_check = ['Language', 'Market']\n",
    "    col_checker = {}\n",
    "    for col in cols_to_check:\n",
    "\n",
    "        if df_summary[col].notnull().values.all() == True:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "\n",
    "    condition_3 = col_checker['Language']\n",
    "    condition_4 = col_checker['Market']\n",
    "    col_condition_2 = all([condition_3, condition_4]) # both conditions has to be true\n",
    "\n",
    "    return col_condition_2, scan_num\n",
    "\n",
    "def col_header_check(df_summary_data, file_initial, sheets):\n",
    "    \n",
    "    # --- SCAN-3 : checking if worker_id column contains _ at the start   -------------------------------------\n",
    "    # PASS -> if the number of character is 10 not 9 and column name is _workder_id\n",
    "    scan_num = 3\n",
    "    find_worker_idx = df_summary_data.columns.str.contains('worker')\n",
    "    worker_idx = [i for i, x in enumerate(find_worker_idx) if x][0]\n",
    "    worker_col = df_summary_data.columns[worker_idx]\n",
    "    worker_col_len = len(worker_col)\n",
    "    \n",
    "    if worker_col_len == 10 and worker_col[0] == \"_\":\n",
    "        col_condition_3 = True\n",
    "    elif worker_col_len == 9 and worker_col[0] == \"w\":\n",
    "        col_condition_3 = False\n",
    "    return col_condition_3, scan_num\n",
    "\n",
    "def data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data'): \n",
    "      \n",
    "    # --- SCAN-4 : checking if \"Data\" sheet contains \"Language\" column   --------------------------------------\n",
    "    # PASS -> 'Data' sheet contains both 'Language' column\n",
    "    scan_num = 4\n",
    "    cols_to_check = ['Language']\n",
    "    col_checker = {}   \n",
    "    for col in cols_to_check:\n",
    "        \n",
    "        if col in df_data_cols:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "            \n",
    "    condition_1 = col_checker['Language']\n",
    "    col_condition_4 = all([condition_1])\n",
    "        \n",
    "    return col_condition_4, scan_num\n",
    "\n",
    "def data_col_value_check(df_data, file_initial, sheets = 'Data'): \n",
    "    \n",
    "    # --- SCAN-5 :checking if \"Language\" column in \"Data\" is empty   -------------------------\n",
    "    # PASS -> 'Language' column in 'Data' contains complete data\n",
    "    scan_num = 5\n",
    "    cols_to_check = ['Language']\n",
    "    col_checker = {}\n",
    "    for col in cols_to_check:\n",
    "\n",
    "        if df_data[col].notnull().values.all() == True:\n",
    "            col_checker[col] = True\n",
    "        else:\n",
    "            col_checker[col] = False\n",
    "\n",
    "    condition_3 = col_checker['Language']\n",
    "    col_condition_5 = all([condition_3])\n",
    "\n",
    "    return col_condition_5, scan_num\n",
    "\n",
    "def data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data'):\n",
    "    \n",
    "    # --- SCAN-7 : checking if columns in \"Data\" sheet are identical to the reference columns   ------------------------\n",
    "    # refer to the file in reference > reference_checks.xlsx\n",
    "    # PASS -> if the two column lists are identical\n",
    "    scan_num = 7\n",
    "    ref_data_cols_sorted = ref_data_cols\n",
    "    df_data_cols_sorted = df_data_cols\n",
    "    \n",
    "    # sorting both the lists \n",
    "    ref_data_cols_sorted.sort() \n",
    "    df_data_cols_sorted.sort() \n",
    "    \n",
    "    # using == to check if  \n",
    "    if ref_data_cols_sorted == df_data_cols_sorted:\n",
    "        col_condition_7 = True\n",
    "    else : \n",
    "        col_condition_7 = False\n",
    "    return col_condition_7, scan_num\n",
    "\n",
    "def data_integrity_check(df_summary, df_summary_cols, df_data, df_data_cols, file_initial): \n",
    "    \n",
    "    print(color.BOLD + f\"Reading {file_initial} raw data and perform data integrity scanning...:\\n\" + color.END)\n",
    "      \n",
    "    conditions_list = []\n",
    "    \n",
    "    # SCAN-1\n",
    "    col_condition_1, scan_num = summary_col_check(df_summary, df_summary_cols, file_initial , 'Summary')\n",
    "    print_scan_results(col_condition_1, scan_num, file_initial , sheets = 'Summary')\n",
    "    conditions_list.append(col_condition_1)\n",
    "      \n",
    "    # SCAN-2\n",
    "    # Runs only when col_condition_1 returns True\n",
    "    if col_condition_1 == True:\n",
    "        col_condition_2, scan_num = summary_col_value_check(df_summary, file_initial, 'Summary')  \n",
    "        print_scan_results(col_condition_2, scan_num, file_initial , sheets = 'Summary')\n",
    "        conditions_list.append(col_condition_2)\n",
    "    else:\n",
    "        conditions_list = conditions_list\n",
    "\n",
    "    # SCAN-3\n",
    "    col_condition_3, scan_num = col_header_check(df_summary, file_initial, 'Summary')\n",
    "    print_scan_results(col_condition_3, scan_num, file_initial , sheets = 'Summary')\n",
    "    conditions_list.append(col_condition_3)\n",
    "    \n",
    "    # SCAN-4\n",
    "    col_condition_4, scan_num = data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data')\n",
    "    print_scan_results(col_condition_4, scan_num, file_initial , sheets = 'Data')\n",
    "    conditions_list.append(col_condition_4)\n",
    "    \n",
    "    # SCAN-5\n",
    "    # Runs only when col_condition_4 returns True\n",
    "    if col_condition_4 == True:\n",
    "        col_condition_5, scan_num = data_col_value_check(df_data, file_initial, sheets = 'Data')\n",
    "        print_scan_results(col_condition_5, scan_num, file_initial , sheets = 'Data')\n",
    "        conditions_list.append(col_condition_5)\n",
    "    else:\n",
    "        conditions_list = conditions_list\n",
    "        \n",
    "    # SCAN-6 \n",
    "    col_condition_6, scan_num = col_header_check(df_data, file_initial, 'Data')\n",
    "    scan_num = 6\n",
    "    print_scan_results(col_condition_6, scan_num, file_initial , 'Data')\n",
    "    conditions_list.append(col_condition_6)\n",
    "    \n",
    "    # SCAN-7\n",
    "    if file_initial == 'RC':\n",
    "        col_condition_7, scan_num = data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data')\n",
    "        print_scan_results(col_condition_7, scan_num, file_initial , 'Data')\n",
    "        conditions_list.append(col_condition_7)\n",
    "       \n",
    "    # Final data integrity results after all checks\n",
    "    # PASS -> when all scans return True/PASS\n",
    "    if len(conditions_list) > 1 :\n",
    "        integrity_result = all(conditions_list)\n",
    "        if integrity_result == True:\n",
    "            print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.GREEN + ' PASS' + color.END + '\\n')\n",
    "        else: \n",
    "            print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.RED + ' FAIL' + color.END + '\\n')\n",
    "    elif len(conditions_list) == 1: \n",
    "        print(color.BOLD + f'\\n{file_initial} data integrity result:' + color.RED + ' FAIL' + color.END + '\\n')\n",
    "\n",
    "    return integrity_result, conditions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing data cleaning step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_initialize(file_exists):\n",
    "\n",
    "    while True:\n",
    "        L_M_input_response = input(\"Do you know the 'Language' and/or 'Market code' for this file? (y/n) : \").lower()\n",
    "        if L_M_input_response == \"y\" or L_M_input_response == \"yes\":\n",
    "            language = input(\"\\nPlease enter the Language: \").capitalize()\n",
    "            market = input(\"\\nPlease enter the Market code: eg. EN-EN for English : \").upper()\n",
    "            break\n",
    "        elif L_M_input_response == \"n\" or L_M_input_response == \"no\":\n",
    "            prefill_response = input(\"\\nWould you like a suggestion for Language (extracted from filename)? (y/n) : \").lower()\n",
    "            if prefill_response == \"y\" or prefill_response == \"yes\":\n",
    "\n",
    "                #filename = file_exists['RC']\n",
    "                language = file_exists['RC'].split(\"_RC\")[0]\n",
    "\n",
    "                language_suggest = input(f\"\\nThe suggested language is : {language} . Do you accept this suggestion? (y/n) : \").lower()\n",
    "\n",
    "                if language_suggest == \"y\" or language_suggest == \"yes\":\n",
    "                    language = language\n",
    "                    prefill_response_m = input(\"\\nWould you like a default prefill for Market (XX-XX). This will only serve as a temporary value, \\\n",
    "please change this as soon as the actual value is known ? (y/n) : \").lower()\n",
    "                    if prefill_response_m == \"y\" or prefill_response_m == \"yes\":  \n",
    "                        market = \"XX-XX\"\n",
    "                        break\n",
    "                    elif prefill_response_m == \"n\" or prefill_response_m == \"no\":   \n",
    "                        print(\"\\nPlease find out the Language and Market code before proceeding - automated data cleaning will NOT be performed. \\n\")\n",
    "                        language, market = '',''\n",
    "                        break\n",
    "                    break\n",
    "                elif language_suggest == \"n\" or language_suggest == \"no\":\n",
    "                    print(\"\\nPlease find out the Language and Market code before proceeding - automated data cleaning will NOT be performed. \\n\")\n",
    "                    language, market = '',''\n",
    "                    break\n",
    "\n",
    "                break\n",
    "            elif prefill_response == \"n\" or prefill_response == \"no\":     \n",
    "                print(\"\\nPlease find out the Language and Market code before proceeding - automated data cleaning will NOT be performed. \\n\")\n",
    "                language, market = '',''\n",
    "                break\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nPlease enter either 'y' or 'n' only!\")\n",
    "            \n",
    "    return language, market\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy data cleaning step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_deploy(file_initials, language, market):\n",
    "    \n",
    "    # check that language and market is not empty\n",
    "    if language != '' and market != '':\n",
    "\n",
    "        # check that language input is consistent with the filename\n",
    "        file_language = file_exists['RC'].split(\"_RC\")[0]\n",
    "        if language == file_language :\n",
    "\n",
    "            print('Starting automated data cleaning....')\n",
    "\n",
    "            for file_initial in file_initials:\n",
    "\n",
    "                clean_data_all(file_initial, language, market)\n",
    "\n",
    "            print(\"Automated data cleaning completed. Cleaned excel files are located in data>processed folder. \\n\")\n",
    "\n",
    "        else:\n",
    "            print('\\nWARNING: Language input is inconsistent with the filename!\\n')\n",
    "            print(f'Input Language: {language}')\n",
    "            print(f'File Language: {file_language}')\n",
    "            lang_check = input(\"\\nWould you like to default the language name as per the filename? (y/n) : \").lower()\n",
    "            if lang_check == \"y\" or lang_check == \"yes\":\n",
    "                language, market = file_language, 'XX-XX'\n",
    "                print(f'\\nLanguage has been set to: {file_language}')\n",
    "                print(f'Temporary market code has been set to: {market}\\n')\n",
    "\n",
    "                print('Starting automated data cleaning....')\n",
    "\n",
    "                for file_initial in file_initials:\n",
    "\n",
    "                    clean_data_all(file_initial, language, market)\n",
    "\n",
    "                print(\"Automated data cleaning completed. Cleaned excel files are located in data>processed folder. \\n\")\n",
    "\n",
    "            elif lang_check == \"n\" or lang_check == \"no\":\n",
    "                print('Automated data processing will not run due to language inconsistency. Please try again.')\n",
    "    else:\n",
    "\n",
    "        print('The values for Language and Market must be known before initializing automated data cleaning!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))\n",
    "    \n",
    "    \n",
    "def clean_summary_sheet(df_summary, df_summary_cols, file_initial, language, market):\n",
    "    \n",
    "    # SCAN-1 - only run if condition is False / FAIL\n",
    "    col_condition_1, scan_num = summary_col_check(df_summary, df_summary_cols, file_initial , 'Summary')\n",
    "    \n",
    "    if col_condition_1 == False:\n",
    "\n",
    "        print(\"Language and Market columns and values inserted to 'Summary' sheet\")\n",
    "        # make a copy of df_summary\n",
    "        df_summary_cleaned = df_summary\n",
    "\n",
    "        # insert \"Language\" and \"Market\" columns into \"Summary\" sheet\n",
    "        # values are defined in the input arguments\n",
    "        df_summary_cleaned.insert(0, 'Language', language)\n",
    "        df_summary_cleaned.insert(1, 'Market', market)\n",
    "        df_summary_cleaned_cols = list(df_summary_cleaned.columns)\n",
    "        \n",
    "        \n",
    "        #rescan SCAN-1 and SCAN-2\n",
    "        summary_col_check(df_summary, df_summary_cols, file_initial , 'Summary')\n",
    "        summary_col_value_check(df_summary, file_initial, sheets = 'Summary')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        df_summary_cleaned = df_summary\n",
    "    \n",
    "    # SCAN-3 - only run if condition is False / FAIL\n",
    "    col_condition_3, scan_num = col_header_check(df_summary_cleaned, file_initial, 'Summary')\n",
    "    \n",
    "    if col_condition_3 == False:\n",
    "        \n",
    "        print(\"Column name worker_id replaced with _worker_id\")\n",
    "        find_worker_idx = df_summary_cleaned.columns.str.contains('worker')\n",
    "        worker_idx = [i for i, x in enumerate(find_worker_idx) if x][0]\n",
    "        worker_col = df_summary_cleaned.columns[worker_idx]\n",
    "        \n",
    "        # replacing column name worker_id with _worker_id\n",
    "        df_summary_cleaned = df_summary_cleaned.rename(columns={worker_col: \"_worker_id\"})\n",
    "        \n",
    "        #rescan SCAN-3\n",
    "        col_header_check(df_summary_cleaned, file_initial, 'Summary')\n",
    "        \n",
    "    return df_summary_cleaned\n",
    "\n",
    "def clean_RC_data_sheet_columns(df_data_cleaned, ref_data):\n",
    "    \n",
    "    df_data_col_add = df_data_cleaned\n",
    "    \n",
    "    ref_data = pd.read_excel(io = ref_filepath, sheet_name=\"columns_check\", header=None)\n",
    "    ref_data_cols = ref_data[0].tolist()\n",
    "    \n",
    "    # enumerate ref_data cols to get the location in list\n",
    "    ref_data_cols_enum = enumerate(ref_data_cols , start=0)\n",
    "    ref_data_cols_enum = list(ref_data_cols_enum)\n",
    "    \n",
    "    df_data_cols = list(df_data_cleaned.columns)\n",
    "    \n",
    "    # find the index and values of missing columns in df_data_column against the ref_data. \n",
    "    #difference_list = [x for x in ref_data_cols if x not in set(df_data_cols)]\n",
    "    difference_list = []\n",
    "    for x in range(len(ref_data_cols_enum)):\n",
    "        idx = ref_data_cols_enum[x][0]\n",
    "        value_to_check = ref_data_cols_enum[x][1]\n",
    "        if value_to_check not in set(df_data_cols):\n",
    "            difference_list.append((idx, value_to_check))\n",
    "    \n",
    "    # insert the missing columns into the df_data dataframe\n",
    "    idxs, col_names = zip(*difference_list)\n",
    "    for idx, col_name in zip(idxs, col_names) :\n",
    "        df_data_col_add.insert(idx, col_name, np.nan)\n",
    "\n",
    "    return df_data_col_add\n",
    "\n",
    "def clean_V_data_sheet_columns(df_data_cleaned):\n",
    "    \n",
    "    df_data_col_rem = df_data_cleaned\n",
    "    selected_cols = df_data_col_rem.columns.tolist()[2:5]\n",
    "    \n",
    "    null_test_results = []\n",
    "    for i in range(len(selected_cols)):\n",
    "        col_iteration = df_data_col_rem[selected_cols[i]]\n",
    "        if col_iteration.notnull().values.all() == True:\n",
    "            null_test = False\n",
    "            null_test_results.append((selected_cols[i], null_test))\n",
    "            df_data_col_rem = df_data_col_rem.rename(columns={selected_cols[i]: \"rater_answer\"})\n",
    "        else:\n",
    "            null_test = True\n",
    "            null_test_results.append((selected_cols[i], null_test))\n",
    "            df_data_col_rem.drop(selected_cols[i], axis = 1, inplace = True)\n",
    "    \n",
    "    return df_data_col_rem\n",
    "     \n",
    "def clean_data_sheet(df_data, df_data_cols, file_initial, language, market):\n",
    "\n",
    "    # SCAN-4 - only run if condition is False / FAIL\n",
    "    col_condition_4, scan_num = data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data')\n",
    "        \n",
    "    if col_condition_4 == False:\n",
    "        \n",
    "        print(\"Language column and values inserted to 'Data' sheet\")\n",
    "        # make a copy of df_data\n",
    "        df_data_cleaned = df_data\n",
    "        \n",
    "        # insert \"Language\" columns into \"Data\" sheet\n",
    "        df_data_cleaned.insert(0, 'Language', language)\n",
    "        df_data_cleaned_cols = list(df_data_cleaned.columns)\n",
    "        \n",
    "        #rescan SCAN-4 and SCAN-5\n",
    "        data_col_check(df_data, df_data_cols, file_initial, sheets = 'Data')\n",
    "        data_col_value_check(df_data, file_initial, sheets = 'Data')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_data_cleaned = df_data\n",
    "        \n",
    "    # SCAN-6 - only run if condition is False / FAIL\n",
    "    col_condition_6, scan_num = col_header_check(df_data_cleaned, file_initial, 'Data')\n",
    "    scan_num = 6\n",
    "    \n",
    "    if col_condition_6 == False:\n",
    "        \n",
    "        print(\"Column name worker_id replaced with _worker_id\")\n",
    "        find_worker_idx_2 = df_data_cleaned.columns.str.contains('worker')\n",
    "        worker_idx_2 = [i for i, x in enumerate(find_worker_idx_2) if x][0]\n",
    "        worker_col_2 = df_data_cleaned.columns[worker_idx_2]\n",
    "        \n",
    "        # replacing column name worker_id with _worker_id\n",
    "        df_data_cleaned = df_data_cleaned.rename(columns={worker_col_2: \"_worker_id\"})\n",
    "        \n",
    "        #rescan SCAN-6\n",
    "        col_header_check(df_data_cleaned, file_initial, 'Data')\n",
    "           \n",
    "    if file_initial == 'RC':      \n",
    "        \n",
    "        # SCAN-7 - only run if condition is False / FAIL\n",
    "        col_condition_7, scan_num = data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data')\n",
    "    \n",
    "        if col_condition_7 == False:\n",
    "\n",
    "            print(\"Missing columns inserted into 'Data' sheet.\")\n",
    "            df_data_cleaned = clean_RC_data_sheet_columns(df_data_cleaned, ref_data_cols)\n",
    "            df_data_cleaned_cols = list(df_data_cleaned.columns)\n",
    "\n",
    "            # rescan SCAN-7\n",
    "            data_col_header_check(df_data_cols, ref_data_cols, file_initial, sheets = 'Data')\n",
    "            \n",
    "    if file_initial == 'Vocab_1' or file_initial == 'Vocab_2':\n",
    "        \n",
    "        print(f\"Removing unwanted columns from {file_initial} Data sheet\")\n",
    "        df_data_cleaned = clean_V_data_sheet_columns(df_data_cleaned)\n",
    "    \n",
    "    return df_data_cleaned\n",
    "\n",
    "def write_to_excel(file_initial, out_data_path, file_exists, df_summary_cleaned, df_data_cleaned, df_ans_key, encode=None):\n",
    "\n",
    "    if file_initial == 'RC' :\n",
    "        with pd.ExcelWriter(os.path.join(out_data_path, file_exists['RC'].split('.')[0] + '.xlsx')) as writer:  \n",
    "            df_summary_cleaned.to_excel(writer, sheet_name='Summary', index=False, encoding=encode)\n",
    "            df_data_cleaned.to_excel(writer, sheet_name='Data', index=False, encoding=encode)\n",
    "            df_ans_key.to_excel(writer, sheet_name='Answer Key', index=False, encoding=encode)\n",
    "\n",
    "    if file_initial == 'Vocab_1' :\n",
    "        with pd.ExcelWriter(os.path.join(out_data_path, file_exists['Vocab_1'].split('.')[0] + '.xlsx')) as writer:  \n",
    "            df_summary_cleaned.to_excel(writer, sheet_name='Summary', index=False, encoding=encode)\n",
    "            df_data_cleaned.to_excel(writer, sheet_name='Data', index=False, encoding=encode)\n",
    "            df_ans_key.to_excel(writer, sheet_name='Answer Key', index=False, encoding=encode)\n",
    "\n",
    "    if file_initial == 'Vocab_2' :\n",
    "        with pd.ExcelWriter(os.path.join(out_data_path, file_exists['Vocab_2'].split('.')[0] + '.xlsx')) as writer:  \n",
    "            df_summary_cleaned.to_excel(writer, sheet_name='Summary', index=False, encoding=encode)\n",
    "            df_data_cleaned.to_excel(writer, sheet_name='Data', index=False, encoding=encode)\n",
    "            df_ans_key.to_excel(writer, sheet_name='Answer Key', index=False, encoding=encode)\n",
    "\n",
    "def clean_data(file_initial, language, market): \n",
    "    \n",
    "    df_summary, df_summary_cols, df_data, df_data_cols, df_ans_key, df_ans_key_cols = create_dataframes(file_initial, rc_filepath, v1_filepath , v2_filepath)\n",
    "    \n",
    "    # Clean Summary sheet\n",
    "    df_summary_cleaned = clean_summary_sheet(df_summary, df_summary_cols, file_initial, language, market)\n",
    "    df_summary_cleaned_cols = list(df_summary_cleaned.columns)\n",
    "           \n",
    "    # Clean Data sheet\n",
    "    df_data_cleaned = clean_data_sheet(df_data, df_data_cols, file_initial, language, market)\n",
    "    df_data_cleaned_cols = list(df_data_cleaned.columns)\n",
    "\n",
    "    print('\\nPreview cleaned datasets:\\n')\n",
    "    dfs = [df_summary_cleaned.iloc[:,:7].head(), df_data_cleaned.iloc[:,:7].head()]\n",
    "    captions = ['df_summary_cleaned', 'df_data_cleaned']\n",
    "    display_df_side_by_side(dfs, captions)\n",
    "    \n",
    "    # Get cleaned datasets integrity report\n",
    "    print('\\nData integrity report post clean-up:\\n')\n",
    "    data_integrity_check(df_summary_cleaned, df_summary_cleaned_cols, df_data_cleaned, df_data_cleaned_cols, file_initial)\n",
    "        \n",
    "    return df_summary_cleaned, df_data_cleaned, df_ans_key\n",
    "\n",
    "#file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "\n",
    "def clean_data_all(file_initial, language, market):\n",
    "\n",
    "    df_summary_cleaned, df_data_cleaned, df_ans_key  = clean_data(file_initial, language, market)\n",
    "    write_to_excel(file_initial, out_data_path, file_exists, df_summary_cleaned, df_data_cleaned, df_ans_key, encode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you know the 'Language' and/or 'Market code' for this file? (y/n) :  y\n",
      "\n",
      "Please enter the Language:  Indonesian\n",
      "\n",
      "Please enter the Market code: eg. EN-EN for English :  Indonesian\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automated data cleaning....\n",
      "Dataframe created from RC file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Missing columns inserted into 'Data' sheet.\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_fa39d_\" style='display:inline'><caption>df_summary_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >Market</th>        <th class=\"col_heading level0 col2\" >_worker_id</th>        <th class=\"col_heading level0 col3\" >Score</th>        <th class=\"col_heading level0 col4\" >Percentage</th>        <th class=\"col_heading level0 col5\" >Grouping</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fa39d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_fa39d_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_fa39d_row0_col1\" class=\"data row0 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_fa39d_row0_col2\" class=\"data row0 col2\" >45360260</td>\n",
       "                        <td id=\"T_fa39d_row0_col3\" class=\"data row0 col3\" >9</td>\n",
       "                        <td id=\"T_fa39d_row0_col4\" class=\"data row0 col4\" >0.750000</td>\n",
       "                        <td id=\"T_fa39d_row0_col5\" class=\"data row0 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fa39d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_fa39d_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_fa39d_row1_col1\" class=\"data row1 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_fa39d_row1_col2\" class=\"data row1 col2\" >45361251</td>\n",
       "                        <td id=\"T_fa39d_row1_col3\" class=\"data row1 col3\" >9</td>\n",
       "                        <td id=\"T_fa39d_row1_col4\" class=\"data row1 col4\" >0.750000</td>\n",
       "                        <td id=\"T_fa39d_row1_col5\" class=\"data row1 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fa39d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_fa39d_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_fa39d_row2_col1\" class=\"data row2 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_fa39d_row2_col2\" class=\"data row2 col2\" >45496367</td>\n",
       "                        <td id=\"T_fa39d_row2_col3\" class=\"data row2 col3\" >7</td>\n",
       "                        <td id=\"T_fa39d_row2_col4\" class=\"data row2 col4\" >0.583333</td>\n",
       "                        <td id=\"T_fa39d_row2_col5\" class=\"data row2 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fa39d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_fa39d_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_fa39d_row3_col1\" class=\"data row3 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_fa39d_row3_col2\" class=\"data row3 col2\" >45496590</td>\n",
       "                        <td id=\"T_fa39d_row3_col3\" class=\"data row3 col3\" >7</td>\n",
       "                        <td id=\"T_fa39d_row3_col4\" class=\"data row3 col4\" >0.583333</td>\n",
       "                        <td id=\"T_fa39d_row3_col5\" class=\"data row3 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fa39d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_fa39d_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_fa39d_row4_col1\" class=\"data row4 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_fa39d_row4_col2\" class=\"data row4 col2\" >45630496</td>\n",
       "                        <td id=\"T_fa39d_row4_col3\" class=\"data row4 col3\" >5</td>\n",
       "                        <td id=\"T_fa39d_row4_col4\" class=\"data row4 col4\" >0.416667</td>\n",
       "                        <td id=\"T_fa39d_row4_col5\" class=\"data row4 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "    </tbody></table>   <style  type=\"text/css\" >\n",
       "</style><table id=\"T_f86a5_\" style='display:inline'><caption>df_data_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >_id</th>        <th class=\"col_heading level0 col2\" >question_no_1</th>        <th class=\"col_heading level0 col3\" >question_no_2</th>        <th class=\"col_heading level0 col4\" >question_no_3</th>        <th class=\"col_heading level0 col5\" >question_no_4</th>        <th class=\"col_heading level0 col6\" >question_no_5</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f86a5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f86a5_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_f86a5_row0_col1\" class=\"data row0 col1\" >5868431995</td>\n",
       "                        <td id=\"T_f86a5_row0_col2\" class=\"data row0 col2\" >a</td>\n",
       "                        <td id=\"T_f86a5_row0_col3\" class=\"data row0 col3\" >c</td>\n",
       "                        <td id=\"T_f86a5_row0_col4\" class=\"data row0 col4\" >b</td>\n",
       "                        <td id=\"T_f86a5_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "                        <td id=\"T_f86a5_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f86a5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f86a5_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_f86a5_row1_col1\" class=\"data row1 col1\" >5868432549</td>\n",
       "                        <td id=\"T_f86a5_row1_col2\" class=\"data row1 col2\" >a</td>\n",
       "                        <td id=\"T_f86a5_row1_col3\" class=\"data row1 col3\" >c</td>\n",
       "                        <td id=\"T_f86a5_row1_col4\" class=\"data row1 col4\" >a</td>\n",
       "                        <td id=\"T_f86a5_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "                        <td id=\"T_f86a5_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f86a5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f86a5_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_f86a5_row2_col1\" class=\"data row2 col1\" >5868445272</td>\n",
       "                        <td id=\"T_f86a5_row2_col2\" class=\"data row2 col2\" >a</td>\n",
       "                        <td id=\"T_f86a5_row2_col3\" class=\"data row2 col3\" >c</td>\n",
       "                        <td id=\"T_f86a5_row2_col4\" class=\"data row2 col4\" >b</td>\n",
       "                        <td id=\"T_f86a5_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "                        <td id=\"T_f86a5_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f86a5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f86a5_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_f86a5_row3_col1\" class=\"data row3 col1\" >5868445718</td>\n",
       "                        <td id=\"T_f86a5_row3_col2\" class=\"data row3 col2\" >a</td>\n",
       "                        <td id=\"T_f86a5_row3_col3\" class=\"data row3 col3\" >c</td>\n",
       "                        <td id=\"T_f86a5_row3_col4\" class=\"data row3 col4\" >a</td>\n",
       "                        <td id=\"T_f86a5_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "                        <td id=\"T_f86a5_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f86a5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f86a5_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_f86a5_row4_col1\" class=\"data row4 col1\" >5868446482</td>\n",
       "                        <td id=\"T_f86a5_row4_col2\" class=\"data row4 col2\" >a</td>\n",
       "                        <td id=\"T_f86a5_row4_col3\" class=\"data row4 col3\" >b</td>\n",
       "                        <td id=\"T_f86a5_row4_col4\" class=\"data row4 col4\" >a</td>\n",
       "                        <td id=\"T_f86a5_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "                        <td id=\"T_f86a5_row4_col6\" class=\"data row4 col6\" >nan</td>\n",
       "            </tr>\n",
       "    </tbody></table>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : RC - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : RC - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[92mPASS\u001b[0m: The columns in the 'Data' sheet are identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Column name worker_id replaced with _worker_id\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_1 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0b353_\" style='display:inline'><caption>df_summary_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >Market</th>        <th class=\"col_heading level0 col2\" >_worker_id</th>        <th class=\"col_heading level0 col3\" >Score</th>        <th class=\"col_heading level0 col4\" >Percentage</th>        <th class=\"col_heading level0 col5\" >Grouping</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0b353_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_0b353_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_0b353_row0_col1\" class=\"data row0 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_0b353_row0_col2\" class=\"data row0 col2\" >45360260</td>\n",
       "                        <td id=\"T_0b353_row0_col3\" class=\"data row0 col3\" >18</td>\n",
       "                        <td id=\"T_0b353_row0_col4\" class=\"data row0 col4\" >0.900000</td>\n",
       "                        <td id=\"T_0b353_row0_col5\" class=\"data row0 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b353_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_0b353_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_0b353_row1_col1\" class=\"data row1 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_0b353_row1_col2\" class=\"data row1 col2\" >45361251</td>\n",
       "                        <td id=\"T_0b353_row1_col3\" class=\"data row1 col3\" >17</td>\n",
       "                        <td id=\"T_0b353_row1_col4\" class=\"data row1 col4\" >0.850000</td>\n",
       "                        <td id=\"T_0b353_row1_col5\" class=\"data row1 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b353_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_0b353_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_0b353_row2_col1\" class=\"data row2 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_0b353_row2_col2\" class=\"data row2 col2\" >45496367</td>\n",
       "                        <td id=\"T_0b353_row2_col3\" class=\"data row2 col3\" >18</td>\n",
       "                        <td id=\"T_0b353_row2_col4\" class=\"data row2 col4\" >0.900000</td>\n",
       "                        <td id=\"T_0b353_row2_col5\" class=\"data row2 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b353_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_0b353_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_0b353_row3_col1\" class=\"data row3 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_0b353_row3_col2\" class=\"data row3 col2\" >45496590</td>\n",
       "                        <td id=\"T_0b353_row3_col3\" class=\"data row3 col3\" >17</td>\n",
       "                        <td id=\"T_0b353_row3_col4\" class=\"data row3 col4\" >0.850000</td>\n",
       "                        <td id=\"T_0b353_row3_col5\" class=\"data row3 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b353_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_0b353_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_0b353_row4_col1\" class=\"data row4 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_0b353_row4_col2\" class=\"data row4 col2\" >45630496</td>\n",
       "                        <td id=\"T_0b353_row4_col3\" class=\"data row4 col3\" >19</td>\n",
       "                        <td id=\"T_0b353_row4_col4\" class=\"data row4 col4\" >0.950000</td>\n",
       "                        <td id=\"T_0b353_row4_col5\" class=\"data row4 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "    </tbody></table>   <style  type=\"text/css\" >\n",
       "</style><table id=\"T_e4b06_\" style='display:inline'><caption>df_data_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >_id</th>        <th class=\"col_heading level0 col2\" >rater_answer</th>        <th class=\"col_heading level0 col3\" >a_domain</th>        <th class=\"col_heading level0 col4\" >a_register</th>        <th class=\"col_heading level0 col5\" >b_domain</th>        <th class=\"col_heading level0 col6\" >b_register</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e4b06_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e4b06_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_e4b06_row0_col1\" class=\"data row0 col1\" >5868416492</td>\n",
       "                        <td id=\"T_e4b06_row0_col2\" class=\"data row0 col2\" >no</td>\n",
       "                        <td id=\"T_e4b06_row0_col3\" class=\"data row0 col3\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row0_col4\" class=\"data row0 col4\" >neutral</td>\n",
       "                        <td id=\"T_e4b06_row0_col5\" class=\"data row0 col5\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row0_col6\" class=\"data row0 col6\" >neutral</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4b06_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e4b06_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_e4b06_row1_col1\" class=\"data row1 col1\" >5868418444</td>\n",
       "                        <td id=\"T_e4b06_row1_col2\" class=\"data row1 col2\" >no</td>\n",
       "                        <td id=\"T_e4b06_row1_col3\" class=\"data row1 col3\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row1_col4\" class=\"data row1 col4\" >neutral</td>\n",
       "                        <td id=\"T_e4b06_row1_col5\" class=\"data row1 col5\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row1_col6\" class=\"data row1 col6\" >neutral</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4b06_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e4b06_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_e4b06_row2_col1\" class=\"data row2 col1\" >5868418802</td>\n",
       "                        <td id=\"T_e4b06_row2_col2\" class=\"data row2 col2\" >no</td>\n",
       "                        <td id=\"T_e4b06_row2_col3\" class=\"data row2 col3\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row2_col4\" class=\"data row2 col4\" >neutral</td>\n",
       "                        <td id=\"T_e4b06_row2_col5\" class=\"data row2 col5\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row2_col6\" class=\"data row2 col6\" >neutral</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4b06_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e4b06_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_e4b06_row3_col1\" class=\"data row3 col1\" >5868418927</td>\n",
       "                        <td id=\"T_e4b06_row3_col2\" class=\"data row3 col2\" >no</td>\n",
       "                        <td id=\"T_e4b06_row3_col3\" class=\"data row3 col3\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row3_col4\" class=\"data row3 col4\" >neutral</td>\n",
       "                        <td id=\"T_e4b06_row3_col5\" class=\"data row3 col5\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row3_col6\" class=\"data row3 col6\" >neutral</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4b06_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e4b06_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_e4b06_row4_col1\" class=\"data row4 col1\" >5868420074</td>\n",
       "                        <td id=\"T_e4b06_row4_col2\" class=\"data row4 col2\" >yes</td>\n",
       "                        <td id=\"T_e4b06_row4_col3\" class=\"data row4 col3\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row4_col4\" class=\"data row4 col4\" >neutral</td>\n",
       "                        <td id=\"T_e4b06_row4_col5\" class=\"data row4 col5\" >demeanor/attitude</td>\n",
       "                        <td id=\"T_e4b06_row4_col6\" class=\"data row4 col6\" >neutral</td>\n",
       "            </tr>\n",
       "    </tbody></table>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_1 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_1 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Column name worker_id replaced with _worker_id\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_2 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a7bea_\" style='display:inline'><caption>df_summary_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >Market</th>        <th class=\"col_heading level0 col2\" >_worker_id</th>        <th class=\"col_heading level0 col3\" >Score</th>        <th class=\"col_heading level0 col4\" >Percentage</th>        <th class=\"col_heading level0 col5\" >Grouping</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a7bea_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a7bea_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_a7bea_row0_col1\" class=\"data row0 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_a7bea_row0_col2\" class=\"data row0 col2\" >45360260</td>\n",
       "                        <td id=\"T_a7bea_row0_col3\" class=\"data row0 col3\" >30</td>\n",
       "                        <td id=\"T_a7bea_row0_col4\" class=\"data row0 col4\" >0.750000</td>\n",
       "                        <td id=\"T_a7bea_row0_col5\" class=\"data row0 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a7bea_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_a7bea_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_a7bea_row1_col1\" class=\"data row1 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_a7bea_row1_col2\" class=\"data row1 col2\" >45361251</td>\n",
       "                        <td id=\"T_a7bea_row1_col3\" class=\"data row1 col3\" >32</td>\n",
       "                        <td id=\"T_a7bea_row1_col4\" class=\"data row1 col4\" >0.800000</td>\n",
       "                        <td id=\"T_a7bea_row1_col5\" class=\"data row1 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a7bea_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_a7bea_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_a7bea_row2_col1\" class=\"data row2 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_a7bea_row2_col2\" class=\"data row2 col2\" >45496367</td>\n",
       "                        <td id=\"T_a7bea_row2_col3\" class=\"data row2 col3\" >30</td>\n",
       "                        <td id=\"T_a7bea_row2_col4\" class=\"data row2 col4\" >0.750000</td>\n",
       "                        <td id=\"T_a7bea_row2_col5\" class=\"data row2 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a7bea_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_a7bea_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_a7bea_row3_col1\" class=\"data row3 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_a7bea_row3_col2\" class=\"data row3 col2\" >45496590</td>\n",
       "                        <td id=\"T_a7bea_row3_col3\" class=\"data row3 col3\" >25</td>\n",
       "                        <td id=\"T_a7bea_row3_col4\" class=\"data row3 col4\" >0.625000</td>\n",
       "                        <td id=\"T_a7bea_row3_col5\" class=\"data row3 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a7bea_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_a7bea_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_a7bea_row4_col1\" class=\"data row4 col1\" >INDONESIAN</td>\n",
       "                        <td id=\"T_a7bea_row4_col2\" class=\"data row4 col2\" >45630496</td>\n",
       "                        <td id=\"T_a7bea_row4_col3\" class=\"data row4 col3\" >34</td>\n",
       "                        <td id=\"T_a7bea_row4_col4\" class=\"data row4 col4\" >0.850000</td>\n",
       "                        <td id=\"T_a7bea_row4_col5\" class=\"data row4 col5\" >Pilot 2</td>\n",
       "            </tr>\n",
       "    </tbody></table>   <style  type=\"text/css\" >\n",
       "</style><table id=\"T_c983c_\" style='display:inline'><caption>df_data_cleaned</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Language</th>        <th class=\"col_heading level0 col1\" >_id</th>        <th class=\"col_heading level0 col2\" >rater_answer</th>        <th class=\"col_heading level0 col3\" >a_domain</th>        <th class=\"col_heading level0 col4\" >a_register</th>        <th class=\"col_heading level0 col5\" >b_domain</th>        <th class=\"col_heading level0 col6\" >b_register</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c983c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c983c_row0_col0\" class=\"data row0 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_c983c_row0_col1\" class=\"data row0 col1\" >5868419633</td>\n",
       "                        <td id=\"T_c983c_row0_col2\" class=\"data row0 col2\" >a_and_b_have_the_same_meaning</td>\n",
       "                        <td id=\"T_c983c_row0_col3\" class=\"data row0 col3\" >personal</td>\n",
       "                        <td id=\"T_c983c_row0_col4\" class=\"data row0 col4\" >slang/informal</td>\n",
       "                        <td id=\"T_c983c_row0_col5\" class=\"data row0 col5\" >personal</td>\n",
       "                        <td id=\"T_c983c_row0_col6\" class=\"data row0 col6\" >slang/informal</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c983c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c983c_row1_col0\" class=\"data row1 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_c983c_row1_col1\" class=\"data row1 col1\" >5868421716</td>\n",
       "                        <td id=\"T_c983c_row1_col2\" class=\"data row1 col2\" >a_and_b_have_the_same_meaning</td>\n",
       "                        <td id=\"T_c983c_row1_col3\" class=\"data row1 col3\" >personal</td>\n",
       "                        <td id=\"T_c983c_row1_col4\" class=\"data row1 col4\" >slang/informal</td>\n",
       "                        <td id=\"T_c983c_row1_col5\" class=\"data row1 col5\" >personal</td>\n",
       "                        <td id=\"T_c983c_row1_col6\" class=\"data row1 col6\" >slang/informal</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c983c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c983c_row2_col0\" class=\"data row2 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_c983c_row2_col1\" class=\"data row2 col1\" >5868425189</td>\n",
       "                        <td id=\"T_c983c_row2_col2\" class=\"data row2 col2\" >a_and_b_have_the_same_meaning</td>\n",
       "                        <td id=\"T_c983c_row2_col3\" class=\"data row2 col3\" >personal</td>\n",
       "                        <td id=\"T_c983c_row2_col4\" class=\"data row2 col4\" >slang/informal</td>\n",
       "                        <td id=\"T_c983c_row2_col5\" class=\"data row2 col5\" >personal</td>\n",
       "                        <td id=\"T_c983c_row2_col6\" class=\"data row2 col6\" >slang/informal</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c983c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c983c_row3_col0\" class=\"data row3 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_c983c_row3_col1\" class=\"data row3 col1\" >5868425760</td>\n",
       "                        <td id=\"T_c983c_row3_col2\" class=\"data row3 col2\" >a_and_b_have_the_same_meaning</td>\n",
       "                        <td id=\"T_c983c_row3_col3\" class=\"data row3 col3\" >personal</td>\n",
       "                        <td id=\"T_c983c_row3_col4\" class=\"data row3 col4\" >slang/informal</td>\n",
       "                        <td id=\"T_c983c_row3_col5\" class=\"data row3 col5\" >personal</td>\n",
       "                        <td id=\"T_c983c_row3_col6\" class=\"data row3 col6\" >slang/informal</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c983c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c983c_row4_col0\" class=\"data row4 col0\" >Indonesian</td>\n",
       "                        <td id=\"T_c983c_row4_col1\" class=\"data row4 col1\" >5868427602</td>\n",
       "                        <td id=\"T_c983c_row4_col2\" class=\"data row4 col2\" >a_and_b_have_the_same_meaning</td>\n",
       "                        <td id=\"T_c983c_row4_col3\" class=\"data row4 col3\" >personal</td>\n",
       "                        <td id=\"T_c983c_row4_col4\" class=\"data row4 col4\" >slang/informal</td>\n",
       "                        <td id=\"T_c983c_row4_col5\" class=\"data row4 col5\" >personal</td>\n",
       "                        <td id=\"T_c983c_row4_col6\" class=\"data row4 col6\" >slang/informal</td>\n",
       "            </tr>\n",
       "    </tbody></table>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_2 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_2 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Automated data cleaning completed. Cleaned excel files are located in data>processed folder. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    file_initials = ['RC', 'Vocab_1', 'Vocab_2']\n",
    "    \n",
    "    language, market = data_cleaning_initialize(file_exists)\n",
    "    data_cleaning_deploy(file_initials, language, market)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
